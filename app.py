import streamlit as st
import pandas as pd
import numpy as np
import io
import re
import altair as alt

# ================= 1. é¡µé¢åŸºç¡€é…ç½® =================
st.set_page_config(
    page_title="åé’TikTok åˆ©æ¶¦æµ‹ç®—ç³»ç»Ÿ (Webç‰ˆ)",
    page_icon="ğŸ’°",
    layout="wide",
    initial_sidebar_state="expanded" 
)

st.markdown("""
    <style>
    .main {background-color: #f8f9fa;}
    div.stButton > button:first-child {
        background-color: #ff0050; color: white; border-radius: 8px; 
        padding: 12px 24px; font-weight: 600; border: none; width: 100%; font-size: 18px;
    }
    div.stButton > button:first-child:hover {background-color: #d60043; color: white;}
    [data-testid="stMetricValue"] {font-size: 24px; font-weight: bold; color: #1e1e1e;}
    
    /* KPI å¡ç‰‡æ ·å¼ */
    .kpi-card {
        background-color: white; padding: 20px; border-radius: 10px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05); margin-bottom: 20px; border: 1px solid #e0e0e0;
    }
    .kpi-title {font-size: 16px; color: #666; margin-bottom: 5px;}
    
    /* æ–‡æœ¬åŸŸæ ·å¼ */
    .stTextArea textarea {font-family: 'Consolas', 'Courier New', monospace; font-size: 14px;}
    </style>
""", unsafe_allow_html=True)

# ================= 2. å…¨å±€é…ç½® =================
EXCHANGE_RATE = 1 / 7.15 

# è¾“å‡ºåˆ—å®šä¹‰
TARGET_COLUMNS_SKU = [
    'SPU', 'SKU', 'ç±»åˆ«', 'é”€é‡', 
    'é€€æ¬¾å‰è¥æ”¶', 'é€€æ¬¾åè¥æ”¶', 
    'åˆ©æ¶¦ç‡', 'åˆ©æ¶¦é¢', 'ASP',
    'è¥ä¸šæˆæœ¬ç‡', 'è¿è¥æˆæœ¬ç‡', 'æ€»è¥é”€è´¹æ¯”',
    'å•ä»¶é‡‡è´­æˆæœ¬', 'å•ä»¶å¤´ç¨‹', 'å•ä»¶å…³ç¨', 'å•ä»¶å°¾ç¨‹', 
    'é€€æ¬¾å•æ•°', 'é€€æ¬¾è¥æ”¶', 'é€€æ¬¾ç‡', 
    'æ€»è¾¾äººä½£é‡‘', 
    'å•ä»¶æ ·å“æˆæœ¬', 'æ€»æ ·å“è´¹', 
    'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹', 
    'é‡‡è´­æˆæœ¬-å æ¯”', 'å¤´ç¨‹-å æ¯”', 'å…³ç¨å æ¯”', 'å°¾ç¨‹-å æ¯”', 
    'ä»“ç§Ÿ-å æ¯”', 'å…¶ä»–ç‰©æµæˆæœ¬-å æ¯”', 'å“ç‰Œè´¹ç”¨-å æ¯”', 'å¹³å°ä½£é‡‘-å æ¯”', 
    'å…¶ä»–å’Œå”®å-å æ¯”', 'è¾¾äººä½£é‡‘-å æ¯”', 'æ ·å“è´¹-å æ¯”', 
    'å¹¿å‘ŠæŠ•æ”¾è´¹-å æ¯”'
]

TARGET_COLUMNS_SPU = [col for col in TARGET_COLUMNS_SKU if col not in [
    'SKU', 'å•ä»¶é‡‡è´­æˆæœ¬', 'å•ä»¶å¤´ç¨‹', 'å•ä»¶å…³ç¨', 'å•ä»¶å°¾ç¨‹', 'å•ä»¶æ ·å“æˆæœ¬'
]]
TARGET_COLUMNS_SHOP = [col for col in TARGET_COLUMNS_SPU if col not in ['SPU', 'ç±»åˆ«']]
TARGET_COLUMNS_SHOP_FINAL = ['æ•°æ®å‘¨æœŸ'] + TARGET_COLUMNS_SHOP

# ================= 3. åŸºç¡€å·¥å…·å‡½æ•° =================

def normalize_headers(df):
    if df is None: return None
    df.columns = df.columns.astype(str).str.replace(r'[\u200b\ufeff]', '', regex=True).str.replace(r'\s+', ' ', regex=True).str.strip()
    return df

def clean_text(df, col_name):
    if col_name in df.columns:
        return df[col_name].astype(str).str.replace(r'[\u200b\ufeff]', '', regex=True).str.strip().str.upper()
    return df[col_name]

def convert_scientific_to_str(val):
    if pd.isna(val): return ""
    try:
        if isinstance(val, (int, float)): return str(int(val))
        s = str(val).strip()
        s = re.sub(r'[\u200b\ufeff]', '', s) 
        if 'E' in s.upper(): return str(int(float(s)))
        if s.endswith('.0'): return s[:-2]
        return s
    except: return str(val).strip()

def clean_money(val):
    if pd.isna(val): return 0
    s = str(val).strip()
    s = re.sub(r'[^\d\.\-]', '', s) 
    try: return float(s)
    except: return 0

def find_col_by_keyword(df, keywords):
    for col in df.columns:
        c_low = str(col).lower()
        if all(k.lower() in c_low for k in keywords):
            return col
    return None

def find_order_id_col(df):
    candidates = ['Order ID', 'Order Id', 'order id', 'order_id', 'è®¢å•å·', 'Main Order ID']
    for c in df.columns:
        if str(c).strip() in candidates: return c
    for c in df.columns:
        if 'order' in str(c).lower() and 'id' in str(c).lower(): return c
    return None

def find_affiliate_sku_col(df):
    for c in df.columns:
        if 'seller' in str(c).lower() and 'sku' in str(c).lower(): return c
    for c in df.columns:
        if 'sku' in str(c).lower() and 'product' not in str(c).lower(): return c
    return None

def get_cost_map(cost_df, keywords):
    if cost_df is None: return {}
    target_col = find_col_by_keyword(cost_df, keywords)
    if not target_col: return {}
    sku_col = find_col_by_keyword(cost_df, ['sku'])
    if not sku_col: return {}
    
    cost_df['SKU_Clean'] = clean_text(cost_df, sku_col)
    cost_df['Clean_Cost'] = cost_df[target_col].apply(clean_money)
    cost_df['USD'] = cost_df['Clean_Cost'] * EXCHANGE_RATE
    return dict(zip(cost_df['SKU_Clean'], cost_df['USD']))

def build_sku_to_spu_dict(df_spu_sku):
    if df_spu_sku is None: return {}
    mapping_dict = {}
    spu_col = find_col_by_keyword(df_spu_sku, ['spu'])
    if not spu_col: return {}
    candidate_cols = [c for c in df_spu_sku.columns if 'sku' in str(c).lower() and c != spu_col]
    for _, row in df_spu_sku.iterrows():
        target_spu = row[spu_col]
        if pd.isna(target_spu) or str(target_spu).strip() == '': continue
        target_spu = str(target_spu).strip()
        for col in candidate_cols:
            sku_val = row[col]
            if pd.notna(sku_val) and str(sku_val).strip() != '':
                mapping_dict[str(sku_val).strip().upper()] = target_spu
    return mapping_dict

def format_dataframe(df, target_columns):
    for col in target_columns:
        if col not in df.columns: df[col] = 0   
    df_out = df.reindex(columns=target_columns, fill_value=0)
    pct_columns = [
        'åˆ©æ¶¦ç‡', 'é€€æ¬¾ç‡', 'æ€»è¥é”€è´¹æ¯”', 'è¥ä¸šæˆæœ¬ç‡', 'è¿è¥æˆæœ¬ç‡',
        'é‡‡è´­æˆæœ¬-å æ¯”', 'å¤´ç¨‹-å æ¯”', 'å…³ç¨å æ¯”', 'å°¾ç¨‹-å æ¯”', 
        'ä»“ç§Ÿ-å æ¯”', 'å…¶ä»–ç‰©æµæˆæœ¬-å æ¯”', 'å“ç‰Œè´¹ç”¨-å æ¯”', 'å¹³å°ä½£é‡‘-å æ¯”', 
        'å…¶ä»–å’Œå”®å-å æ¯”', 'è¾¾äººä½£é‡‘-å æ¯”', 'æ ·å“è´¹-å æ¯”', 'å¹¿å‘ŠæŠ•æ”¾è´¹-å æ¯”'
    ]
    numeric_cols = df_out.select_dtypes(include=[np.number]).columns
    money_cols = [c for c in numeric_cols if c not in pct_columns]
    
    df_out[money_cols] = df_out[money_cols].fillna(0).round(2)
    
    for col in pct_columns:
        if col in df_out.columns:
            df_out[col] = df_out[col].fillna(0).apply(lambda x: f"{x:.2%}")
    return df_out

# ================= 4. æ—¥æœŸå¤„ç†ä¸åˆ†æå¼•æ“ =================

def ensure_date_column(df, label="æœªçŸ¥"):
    if df is None or df.empty: return False
    if 'Date' in df.columns: return True
    
    col_date = 'Created Time'
    if col_date not in df.columns:
        col_date = find_col_by_keyword(df, ['created', 'time', 'date', 'æ—¥æœŸ'])
    
    if col_date and col_date in df.columns:
        try:
            df['Date'] = pd.to_datetime(df[col_date], dayfirst=False, errors='coerce')
            if df['Date'].notna().sum() > 0: return True
            else:
                return False
        except: return False
    return False

def calculate_yoy_metrics(df_current, df_last):
    if not ensure_date_column(df_current, "ä»Šå¹´è®¢å•"): return None
    
    def get_core_stats(df):
        df = df.copy()
        col_rev = 'è¥æ”¶' if 'è¥æ”¶' in df.columns else find_col_by_keyword(df, ['revenue', 'amount'])
        col_qty = 'Quantity' if 'Quantity' in df.columns else find_col_by_keyword(df, ['quantity'])
        col_status = 'Order Status' if 'Order Status' in df.columns else find_col_by_keyword(df, ['status'])
        
        if not col_rev: col_rev = find_col_by_keyword(df, ['amount'])
        if not col_rev or not col_qty: return 0, 0, 0, 0
        
        df[col_rev] = pd.to_numeric(df[col_rev], errors='coerce').fillna(0)
        df[col_qty] = pd.to_numeric(df[col_qty], errors='coerce').fillna(0)
        is_cancelled = df[col_status].astype(str).str.strip().isin(['Cancelled', 'Canceled'])
        
        gmv = df[col_rev].sum()
        net_rev = df.loc[~is_cancelled, col_rev].sum()
        sales_qty = df.loc[~is_cancelled, col_qty].sum()
        refund_rev = df.loc[is_cancelled, col_rev].sum()
        refund_rate = refund_rev / gmv if gmv > 0 else 0
        return gmv, net_rev, sales_qty, refund_rate

    curr_gmv, curr_net, curr_qty, curr_ref_rate = get_core_stats(df_current)
    return {'curr': (curr_gmv, curr_net, curr_qty, curr_ref_rate)}

def get_dual_trend_data(df_curr, df_last):
    if df_curr is None: return None, None
    ensure_date_column(df_curr)
    
    data_biweek = []
    data_monthly = []
    
    def process_df(df, year_label):
        if 'Date' not in df.columns: return
        
        col_rev = 'è¥æ”¶' if 'è¥æ”¶' in df.columns else find_col_by_keyword(df, ['revenue', 'amount'])
        col_status = 'Order Status' if 'Order Status' in df.columns else find_col_by_keyword(df, ['status'])
        
        if col_rev and col_status:
            df[col_rev] = pd.to_numeric(df[col_rev], errors='coerce').fillna(0)
            is_can = df[col_status].astype(str).str.strip().isin(['Cancelled', 'Canceled'])
            df_clean = df[~is_can].copy()
            
            # æœˆåº¦
            df_clean['Month'] = df_clean['Date'].dt.strftime('%m')
            monthly_agg = df_clean.groupby('Month')[col_rev].sum().reset_index()
            for _, row in monthly_agg.iterrows():
                data_monthly.append({'X': row['Month'], 'Revenue': row[col_rev], 'Year': year_label})
                
            # åŒå‘¨
            df_clean['DayOfYear'] = df_clean['Date'].dt.dayofyear
            df_clean['BiWeek'] = (df_clean['DayOfYear'] - 1) // 14 + 1
            biweek_agg = df_clean.groupby('BiWeek')[col_rev].sum().reset_index()
            for _, row in biweek_agg.iterrows():
                label = f"Bi-Week {int(row['BiWeek']):02d}"
                data_biweek.append({'X': label, 'Revenue': row[col_rev], 'Year': year_label})

    process_df(df_curr, 'ä»Šå¹´')
    if df_last is not None and not df_last.empty:
        if ensure_date_column(df_last, "2025è¶‹åŠ¿"):
            process_df(df_last, 'å»å¹´')
            
    return pd.DataFrame(data_biweek), pd.DataFrame(data_monthly)

# ================= 5. æ ¸å¿ƒè®¡ç®—é€»è¾‘ =================

def calculate_metrics_final(df_base):
    df = df_base.copy()
    qty = df['é”€é‡'].replace(0, 1)
    rev_after = df['é€€æ¬¾åè¥æ”¶']
    df['ASP'] = rev_after / qty
    
    if 'Refund_Orders' not in df.columns:
        df['Refund_Orders'] = df['é€€æ¬¾å•æ•°'] if 'é€€æ¬¾å•æ•°' in df.columns else 0
        
    df['é€€æ¬¾è¥æ”¶'] = df['Refund_Orders'] * df['ASP']
    df['é€€æ¬¾å‰è¥æ”¶'] = rev_after + df['é€€æ¬¾è¥æ”¶']
    
    rev_before_safe = df['é€€æ¬¾å‰è¥æ”¶'].replace(0, 1)
    df['é€€æ¬¾ç‡'] = df['é€€æ¬¾è¥æ”¶'] / rev_before_safe
    df['é€€æ¬¾å•æ•°'] = df['Refund_Orders']

    for c in ['æ€»è¾¾äººä½£é‡‘', 'æ€»æ ·å“è´¹', 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹']:
        if c not in df.columns: df[c] = 0
        
    mkt_cost = df['æ€»å¹¿å‘ŠæŠ•æ”¾è´¹'] + df['æ€»è¾¾äººä½£é‡‘'] + df['æ€»æ ·å“è´¹']
    df['æ€»è¥é”€è´¹æ¯”'] = mkt_cost / rev_after.replace(0, 1)

    df['ä»“ç§Ÿ'] = rev_after * 0.005
    df['å…¶ä»–ç‰©æµæˆæœ¬'] = rev_after * 0.003
    df['å“ç‰Œè´¹ç”¨'] = rev_after * 0.003
    df['å¹³å°ä½£é‡‘'] = rev_after * 0.06
    df['å…¶ä»–å’Œå”®å'] = rev_after * 0.003

    for c in ['é‡‡è´­æˆæœ¬', 'å¤´ç¨‹', 'å°¾ç¨‹', 'å…³ç¨']:
        if c not in df.columns: df[c] = 0

    all_costs = sum(df[c] for c in [
        'é‡‡è´­æˆæœ¬', 'å¤´ç¨‹', 'å°¾ç¨‹', 'å…³ç¨', 
        'ä»“ç§Ÿ', 'å…¶ä»–ç‰©æµæˆæœ¬', 'å“ç‰Œè´¹ç”¨', 'å¹³å°ä½£é‡‘', 'å…¶ä»–å’Œå”®å', 
        'æ€»è¾¾äººä½£é‡‘', 'æ€»æ ·å“è´¹', 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹'
    ] if c in df.columns)
    
    df['åˆ©æ¶¦é¢'] = rev_after - all_costs
    df['åˆ©æ¶¦ç‡'] = df['åˆ©æ¶¦é¢'] / rev_after.replace(0, 1)

    rev_safe = rev_after.replace(0, 1)
    cogs = df['é‡‡è´­æˆæœ¬'] + df['å¤´ç¨‹'] + df['å…³ç¨'] + df['å°¾ç¨‹']
    df['è¥ä¸šæˆæœ¬ç‡'] = cogs / rev_safe
    ops_cost = df['ä»“ç§Ÿ'] + df['å…¶ä»–ç‰©æµæˆæœ¬'] + df['å“ç‰Œè´¹ç”¨'] + df['å¹³å°ä½£é‡‘'] + df['å…¶ä»–å’Œå”®å']
    df['è¿è¥æˆæœ¬ç‡'] = ops_cost / rev_safe
    
    ratio_map = {
        'é‡‡è´­æˆæœ¬-å æ¯”': 'é‡‡è´­æˆæœ¬', 'å¤´ç¨‹-å æ¯”': 'å¤´ç¨‹', 'å°¾ç¨‹-å æ¯”': 'å°¾ç¨‹', 'å…³ç¨å æ¯”': 'å…³ç¨',
        'ä»“ç§Ÿ-å æ¯”': 'ä»“ç§Ÿ', 'å…¶ä»–ç‰©æµæˆæœ¬-å æ¯”': 'å…¶ä»–ç‰©æµæˆæœ¬',
        'å“ç‰Œè´¹ç”¨-å æ¯”': 'å“ç‰Œè´¹ç”¨', 'å¹³å°ä½£é‡‘-å æ¯”': 'å¹³å°ä½£é‡‘', 'å…¶ä»–å’Œå”®å-å æ¯”': 'å…¶ä»–å’Œå”®å',
        'è¾¾äººä½£é‡‘-å æ¯”': 'æ€»è¾¾äººä½£é‡‘', 'æ ·å“è´¹-å æ¯”': 'æ€»æ ·å“è´¹', 'å¹¿å‘ŠæŠ•æ”¾è´¹-å æ¯”': 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹',
    }
    for r_col, val_col in ratio_map.items():
        if val_col in df.columns:
            df[r_col] = df[val_col] / rev_safe
        else:
            df[r_col] = 0
            
    return df

def run_calculation_logic(dfs):
    for key, df in dfs.items():
        if df is not None: dfs[key] = normalize_headers(df)
    
    df_orders = dfs['orders']
    if df_orders is None: return None, None, None, "æ— è®¢å•æ•°æ®", None

    col_sku = 'Seller SKU' if 'Seller SKU' in df_orders.columns else 'SKU'
    df_orders[col_sku] = clean_text(df_orders, col_sku)
    df_orders['clean_order_id'] = df_orders['Order ID'].apply(convert_scientific_to_str)
    
    sku_to_spu_dict = build_sku_to_spu_dict(dfs['spu_sku'])
    if sku_to_spu_dict:
        df_orders['SPU'] = df_orders[col_sku].map(sku_to_spu_dict).fillna(df_orders[col_sku])
    else:
        if 'SPU' not in df_orders.columns: df_orders['SPU'] = df_orders[col_sku]

    time_str = "æœªçŸ¥å‘¨æœŸ"
    max_date = None
    if ensure_date_column(df_orders, "ä»Šå¹´è®¢å•"):
        try:
            dates = df_orders['Date'].dropna()
            if not dates.empty:
                time_str = f"{dates.min().strftime('%Y-%m-%d')} ~ {dates.max().strftime('%Y-%m-%d')}"
                max_date = dates.max()
        except: pass

    # === ä½£é‡‘åŒ¹é… ===
    df_orders['Comm'] = 0
    sku_real_comm = None
    df_aff = dfs['affiliate']
    if df_aff is not None:
        aff_id = find_order_id_col(df_aff)
        aff_sku = find_affiliate_sku_col(df_aff)
        std_cols = [c for c in df_aff.columns if 'standard commission' in str(c).lower() and 'payment' in str(c).lower()]
        ads_cols = [c for c in df_aff.columns if 'shop ads commission' in str(c).lower() and 'payment' in str(c).lower()]

        if aff_id and aff_sku and (std_cols or ads_cols):
            df_aff['clean_order_id'] = df_aff[aff_id].apply(convert_scientific_to_str)
            df_aff['Mapped_SKU'] = clean_text(df_aff, aff_sku)
            df_aff['Total_Raw'] = 0
            for c in std_cols + ads_cols: df_aff['Total_Raw'] += df_aff[c].apply(clean_money)
            
            aff_grp = df_aff.groupby(['clean_order_id', 'Mapped_SKU'])['Total_Raw'].sum().reset_index()
            df_orders['sku_weight'] = df_orders.groupby(['clean_order_id', col_sku])['clean_order_id'].transform('count')
            merged = pd.merge(df_orders, aff_grp, left_on=['clean_order_id', col_sku], right_on=['clean_order_id', 'Mapped_SKU'], how='left')
            df_orders['Comm'] = merged['Total_Raw'].fillna(0) / df_orders['sku_weight'].fillna(1)

    sku_real_comm = df_orders.groupby(['SPU', col_sku])['Comm'].sum().reset_index().rename(columns={col_sku: 'SKU', 'Comm': 'æ€»è¾¾äººä½£é‡‘'})

    # === è®¢å•åˆ†ç±» ===
    if 'Order ID' in df_orders.columns:
        df_orders = df_orders[~df_orders['Order ID'].astype(str).str.contains('Platform|Order ID', na=False)]
    
    col_rev = 'è¥æ”¶'
    col_qty = 'Quantity'
    col_status = 'Order Status'
    df_orders[col_rev] = pd.to_numeric(df_orders[col_rev], errors='coerce').fillna(0)
    df_orders[col_qty] = pd.to_numeric(df_orders.get(col_qty, 1), errors='coerce').fillna(0)
    
    is_cancelled = df_orders[col_status].astype(str).str.strip().isin(['Cancelled', 'Canceled'])
    is_normal = (~is_cancelled) & (df_orders[col_rev] > 0)
    is_sample = (~is_cancelled) & (df_orders[col_rev] == 0)
    
    df_normal = df_orders[is_normal].copy()
    df_sample = df_orders[is_sample].copy()
    df_refund = df_orders[is_cancelled].copy()

    # === æˆæœ¬å‡†å¤‡ ===
    map_p = get_cost_map(dfs['purchase'], ['é‡‡è´­', 'CNY'])
    map_h = get_cost_map(dfs['head'], ['å¤´ç¨‹', 'CNY'])
    map_t = get_cost_map(dfs['tail'], ['å°¾ç¨‹', 'CNY'])

    master_skus = df_orders[['SPU', col_sku]].drop_duplicates().rename(columns={col_sku: 'SKU'})

    # === SKU ç»Ÿè®¡ ===
    norm_stat = df_normal.groupby(['SPU', col_sku]).agg({col_rev: 'sum', col_qty: 'sum', 'Product Name': 'first'}).reset_index().rename(columns={col_sku: 'SKU', col_qty: 'é”€é‡', col_rev: 'é€€æ¬¾åè¥æ”¶'})
    sku_stats = pd.merge(master_skus, norm_stat, on=['SPU', 'SKU'], how='left')
    sku_stats[['é”€é‡', 'é€€æ¬¾åè¥æ”¶']] = sku_stats[['é”€é‡', 'é€€æ¬¾åè¥æ”¶']].fillna(0)
    
    if 'Product Name' in df_orders.columns:
        pmap = df_orders.groupby(col_sku)['Product Name'].first().to_dict()
        sku_stats['Product Name'] = sku_stats['Product Name'].fillna(sku_stats['SKU'].map(pmap))

    if not df_refund.empty:
        ref_agg = df_refund.groupby(['SPU', col_sku])[col_qty].sum().reset_index().rename(columns={col_sku: 'SKU', col_qty: 'Refund_Orders'})
        sku_stats = pd.merge(sku_stats, ref_agg, on=['SPU', 'SKU'], how='left')
    else: sku_stats['Refund_Orders'] = 0
    sku_stats['Refund_Orders'] = sku_stats['Refund_Orders'].fillna(0)

    tmp_qty = sku_stats['é”€é‡'].replace(0, 1)
    sku_stats['ASP'] = sku_stats['é€€æ¬¾åè¥æ”¶'] / tmp_qty
    sku_stats.loc[sku_stats['é”€é‡']==0, 'ASP'] = 0
    sku_stats['é€€æ¬¾è¥æ”¶'] = sku_stats['Refund_Orders'] * sku_stats['ASP']
    sku_stats['é€€æ¬¾å‰è¥æ”¶'] = sku_stats['é€€æ¬¾åè¥æ”¶'] + sku_stats['é€€æ¬¾è¥æ”¶']

    # === æ ·å“ä¸æˆæœ¬ ===
    sku_stats['æ€»æ ·å“è´¹'] = 0
    sku_stats['å•ä»¶æ ·å“æˆæœ¬'] = 0
    if not df_sample.empty:
        df_sample['Unit_S'] = df_sample[col_sku].map(map_p).fillna(0) + df_sample[col_sku].map(map_h).fillna(0) + df_sample[col_sku].map(map_t).fillna(0)
        df_sample['Total_S'] = df_sample[col_qty] * df_sample['Unit_S']
        s_agg = df_sample.groupby(['SPU', col_sku])['Total_S'].sum().reset_index().rename(columns={col_sku: 'SKU', 'Total_S': 'æ€»æ ·å“è´¹'})
        u_agg = df_sample.groupby(['SPU', col_sku])['Unit_S'].first().reset_index().rename(columns={col_sku: 'SKU', 'Unit_S': 'å•ä»¶æ ·å“æˆæœ¬'})
        sku_stats = pd.merge(sku_stats, s_agg, on=['SPU', 'SKU'], how='left')
        sku_stats = pd.merge(sku_stats, u_agg, on=['SPU', 'SKU'], how='left')
        if 'æ€»æ ·å“è´¹_y' in sku_stats.columns: sku_stats['æ€»æ ·å“è´¹'] = sku_stats['æ€»æ ·å“è´¹_y'].fillna(0)
        else: sku_stats['æ€»æ ·å“è´¹'] = sku_stats.get('æ€»æ ·å“è´¹', 0).fillna(0)
        if 'å•ä»¶æ ·å“æˆæœ¬_y' in sku_stats.columns: sku_stats['å•ä»¶æ ·å“æˆæœ¬'] = sku_stats['å•ä»¶æ ·å“æˆæœ¬_y'].fillna(0)
        else: sku_stats['å•ä»¶æ ·å“æˆæœ¬'] = sku_stats.get('å•ä»¶æ ·å“æˆæœ¬', 0).fillna(0)

    def fill_sample_unit(row):
        if row['å•ä»¶æ ·å“æˆæœ¬'] == 0: return map_p.get(row['SKU'], 0) + map_h.get(row['SKU'], 0) + map_t.get(row['SKU'], 0)
        return row['å•ä»¶æ ·å“æˆæœ¬']
    sku_stats['å•ä»¶æ ·å“æˆæœ¬'] = sku_stats.apply(fill_sample_unit, axis=1)

    sku_stats['å•ä»¶é‡‡è´­æˆæœ¬'] = sku_stats['SKU'].map(map_p).fillna(0)
    sku_stats['å•ä»¶å¤´ç¨‹'] = sku_stats['SKU'].map(map_h).fillna(0)
    sku_stats['å•ä»¶å°¾ç¨‹'] = sku_stats['SKU'].map(map_t).fillna(0)
    sku_stats['å•ä»¶å…³ç¨'] = 0
    sku_stats['é‡‡è´­æˆæœ¬'] = sku_stats['å•ä»¶é‡‡è´­æˆæœ¬'] * sku_stats['é”€é‡']
    sku_stats['å¤´ç¨‹'] = sku_stats['å•ä»¶å¤´ç¨‹'] * sku_stats['é”€é‡']
    sku_stats['å°¾ç¨‹'] = sku_stats['å•ä»¶å°¾ç¨‹'] * sku_stats['é”€é‡']
    sku_stats['å…³ç¨'] = 0

    sku_stats = pd.merge(sku_stats, sku_real_comm, on=['SPU', 'SKU'], how='left')
    sku_stats['æ€»è¾¾äººä½£é‡‘'] = sku_stats['æ€»è¾¾äººä½£é‡‘'].fillna(0)

    # === å¹¿å‘Šåˆ†æ‘Š ===
    sku_stats['æ€»å¹¿å‘ŠæŠ•æ”¾è´¹'] = 0
    df_ads = dfs['ads']
    df_map = dfs['mapping']
    if df_ads is not None and df_map is not None:
        pid_c = find_col_by_keyword(df_map, ['product_id'])
        sku_mc = find_col_by_keyword(df_map, ['sku'])
        if pid_c and sku_mc:
            df_map[pid_c] = clean_text(df_map, pid_c)
            df_map[sku_mc] = clean_text(df_map, sku_mc)
            pid_grps = df_map.groupby(pid_c)[sku_mc].apply(list).reset_index()
            ad_pid = find_col_by_keyword(df_ads, ['product id'])
            if ad_pid:
                df_ads[ad_pid] = clean_text(df_ads, ad_pid)
                df_ads['Cost'] = pd.to_numeric(df_ads['Cost'], errors='coerce').fillna(0)
                rev_map = dict(zip(sku_stats['SKU'], sku_stats['é€€æ¬¾å‰è¥æ”¶']))
                dist_list = []
                merged_ads = pd.merge(df_ads, pid_grps, left_on=ad_pid, right_on=pid_c, how='inner')
                for _, row in merged_ads.iterrows():
                    cost = row['Cost']
                    skus = row[sku_mc]
                    if not skus: continue
                    revs = {s: rev_map.get(s, 0) for s in skus}
                    tot = sum(revs.values())
                    for s in skus:
                        if tot > 0: share = cost * (revs[s] / tot)
                        else: share = cost / len(skus)
                        dist_list.append({'SKU': s, 'AdsCost': share})
                if dist_list:
                    ads_df = pd.DataFrame(dist_list)
                    ads_agg = ads_df.groupby('SKU')['AdsCost'].sum().reset_index().rename(columns={'AdsCost': 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹'})
                    sku_stats = pd.merge(sku_stats, ads_agg, on='SKU', how='left')
                    if 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹_y' in sku_stats.columns: sku_stats['æ€»å¹¿å‘ŠæŠ•æ”¾è´¹'] = sku_stats['æ€»å¹¿å‘ŠæŠ•æ”¾è´¹_y'].fillna(0)
                    else: sku_stats['æ€»å¹¿å‘ŠæŠ•æ”¾è´¹'] = sku_stats.get('æ€»å¹¿å‘ŠæŠ•æ”¾è´¹', 0).fillna(0)

    # === æ±‡æ€» ===
    df_sku_final = calculate_metrics_final(sku_stats)
    df_sku_out = format_dataframe(df_sku_final, TARGET_COLUMNS_SKU)

    sum_cols = ['é”€é‡', 'é€€æ¬¾åè¥æ”¶', 'é€€æ¬¾å‰è¥æ”¶', 'Refund_Orders', 'é€€æ¬¾è¥æ”¶', 'é‡‡è´­æˆæœ¬', 'å¤´ç¨‹', 'å°¾ç¨‹', 'å…³ç¨', 'ä»“ç§Ÿ', 'å…¶ä»–ç‰©æµæˆæœ¬', 'å“ç‰Œè´¹ç”¨', 'å¹³å°ä½£é‡‘', 'å…¶ä»–å’Œå”®å', 'æ€»è¾¾äººä½£é‡‘', 'æ€»æ ·å“è´¹', 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹']
    spu_agg = sku_stats.groupby('SPU').agg({**{c: 'sum' for c in sum_cols if c in sku_stats.columns}, 'Product Name': 'first'}).reset_index().rename(columns={'Product Name': 'ç±»åˆ«'})
    df_spu_final = calculate_metrics_final(spu_agg).sort_values(by='é€€æ¬¾åè¥æ”¶', ascending=False)
    df_spu_out = format_dataframe(df_spu_final, TARGET_COLUMNS_SPU)

    shop_agg = sku_stats.agg({c: 'sum' for c in sum_cols if c in sku_stats.columns}).to_frame().T
    df_shop_final = calculate_metrics_final(shop_agg)
    df_shop_final['æ•°æ®å‘¨æœŸ'] = time_str
    df_shop_out = format_dataframe(df_shop_final, TARGET_COLUMNS_SHOP_FINAL)

    return df_shop_out, df_spu_out, df_sku_out, time_str, max_date

# ================= 7. æ™ºèƒ½æ–‡ä»¶è¯†åˆ«è¯»å–å™¨ (ä¿®å¤ç‰ˆ V2.3) =================
def load_uploaded_files(uploaded_files):
    dfs = {
        'orders': None, 'orders_last_year': None, 'ads': None, 'affiliate': None,
        'spu_sku': None, 'mapping': None, 'purchase': None, 'head': None, 'tail': None
    }
    status_flags = {k: False for k in dfs.keys()}
    
    for uploaded_file in uploaded_files:
        filename = uploaded_file.name.lower()
        
        try:
            if filename.endswith('.csv'):
                df = pd.read_csv(uploaded_file, dtype=str)
            else:
                df = pd.read_excel(uploaded_file, dtype=str)
        except Exception:
            continue
            
        # ä¿®æ­£é€»è¾‘ï¼šå…³é”®è¯åŒ¹é…ä¼˜å…ˆçº§
        if '2025' in filename or 'å»å¹´' in filename:
            dfs['orders_last_year'] = df
            status_flags['orders_last_year'] = True
        elif 'å¹¿å‘Š' in filename or 'ads' in filename:
            dfs['ads'] = df
            status_flags['ads'] = True
        elif 'è”ç›Ÿ' in filename or 'affiliate' in filename:
            dfs['affiliate'] = df
            status_flags['affiliate'] = True
        elif 'spu' in filename:
            dfs['spu_sku'] = df
            status_flags['spu_sku'] = True
        elif 'pid' in filename or 'mapping' in filename:
            dfs['mapping'] = df
            status_flags['mapping'] = True
        elif 'é‡‡è´­' in filename or 'purchase' in filename:
            dfs['purchase'] = df
            status_flags['purchase'] = True
        elif 'å¤´ç¨‹' in filename or 'head' in filename:
            dfs['head'] = df
            status_flags['head'] = True
        elif 'å°¾ç¨‹' in filename or 'tail' in filename:
            dfs['tail'] = df
            status_flags['tail'] = True
        elif 'è®¢å•' in filename or 'order' in filename:
            # åªæœ‰å½“ä¸æ˜¯ 2025 çš„è®¢å•æ—¶ï¼Œæ‰è®¤ä¸ºæ˜¯ä»Šå¹´çš„
            dfs['orders'] = df
            status_flags['orders'] = True
            
    return dfs, status_flags

# ================= 8. ä¸»ç¨‹åº =================
def main():
    st.title("ğŸš€ åé’ikTok åˆ©æ¶¦æµ‹ç®—ä»ªè¡¨ç›˜ (WebååŒç‰ˆ)")
    
    # --- ä¾§è¾¹æ ï¼šä¸Šä¼ ä¸è®¾ç½® ---
    with st.sidebar:
        st.header("ğŸ“‚ 1. æ‹–æ‹½ä¸Šä¼ æ–‡ä»¶")
        st.info("ğŸ’¡ æç¤ºï¼šä¸€æ¬¡æ€§é€‰ä¸­æ‰€æœ‰æ–‡ä»¶æ‹–è¿›æ¥å³å¯ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«ã€‚")
        
        uploaded_files = st.file_uploader(
            "è¯·ä¸Šä¼ ä¸šåŠ¡æ•°æ®è¡¨ (æ”¯æŒ xlsx/csv)", 
            accept_multiple_files=True,
            type=['xlsx', 'csv']
        )
        
        # å®æ—¶çŠ¶æ€ç¯
        if uploaded_files:
            with st.spinner("â³ æ­£åœ¨æ™ºèƒ½è§£ææ–‡ä»¶ï¼Œè¯·ç¨å€™..."):
                dfs, flags = load_uploaded_files(uploaded_files)
            
            st.markdown("### ğŸ“Š æ–‡ä»¶å°±ä½çŠ¶æ€")
            col_s1, col_s2 = st.columns(2)
            with col_s1:
                st.write(f"{'âœ…' if flags['orders'] else 'âŒ'} ä»Šå¹´è®¢å•")
                st.write(f"{'âœ…' if flags['ads'] else 'âŒ'} å¹¿å‘Šè¡¨")
                st.write(f"{'âœ…' if flags['purchase'] else 'âŒ'} é‡‡è´­æˆæœ¬")
                st.write(f"{'âœ…' if flags['spu_sku'] else 'âŒ'} SPUæ˜ å°„")
            with col_s2:
                st.write(f"{'âœ…' if flags['orders_last_year'] else 'âš ï¸'} 2025è®¢å•")
                st.write(f"{'âœ…' if flags['affiliate'] else 'âŒ'} è”ç›Ÿè¡¨")
                st.write(f"{'âœ…' if flags['head'] else 'âŒ'} å¤´ç¨‹æˆæœ¬")
                st.write(f"{'âœ…' if flags['tail'] else 'âŒ'} å°¾ç¨‹æˆæœ¬")
        else:
            dfs = {}
            flags = {}

        st.divider()
        st.subheader("ğŸ¯ 2. ç›®æ ‡è®¾å®š")
        target_revenue = st.number_input("æœ¬æœˆè¥æ”¶ç›®æ ‡ ($)", value=0.0, step=1000.0)
        target_profit_rate = st.number_input("ç›®æ ‡åˆ©æ¶¦ç‡ (%)", value=15.0, step=0.5) / 100.0

    # ä¸»æ“ä½œæŒ‰é’®
    if st.button("ğŸš€ ç‚¹å‡»å¼€å§‹æµ‹ç®—", type="primary", disabled=not flags.get('orders')):
        st.session_state['has_run'] = True
        
        with st.spinner("â³ æ­£åœ¨è¿›è¡Œï¼šæ•°æ®æ¸…æ´—ã€æ™ºèƒ½åŒ¹é…ã€åˆ©æ¶¦è®¡ç®—..."):
            try:
                df_shop, df_spu, df_sku, time_str, max_date = run_calculation_logic(dfs)
                if df_shop is None:
                    st.error("âŒ è®¢å•è¡¨æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶ã€‚")
                    st.stop()
                    
                st.session_state['data'] = {
                    'dfs': dfs, 
                    'df_shop': df_shop,
                    'df_spu': df_spu,
                    'df_sku': df_sku,
                    'time_str': time_str,
                    'max_date': max_date
                }
            except Exception as e:
                st.error(f"âŒ è¿è¡Œé”™è¯¯: {str(e)}")
                import traceback
                st.code(traceback.format_exc())
                st.session_state['has_run'] = False

    # ç»“æœå±•ç¤ºé¡µé¢
    if st.session_state.get('has_run') and st.session_state.get('data'):
        data = st.session_state['data']
        df_shop = data['df_shop']
        df_spu = data['df_spu']
        df_sku = data['df_sku']
        time_str = data['time_str']
        max_date = data['max_date']
        dfs = data['dfs'] 

        # è®¡ç®— KPI
        shop_row = df_shop.iloc[0]
        curr_rev = shop_row['é€€æ¬¾åè¥æ”¶']
        
        if pd.notna(max_date):
            days_in_month = pd.Period(max_date, freq='M').days_in_month
            time_progress = max_date.day / days_in_month
        else:
            time_progress = 0
            
        mtd_achieve = curr_rev / target_revenue if target_revenue > 0 else 0
        pace_status = "ğŸ”´ è½å" if mtd_achieve < time_progress else "ğŸŸ¢ è¶…å‰"
        
        yoy_data = calculate_yoy_metrics(dfs['orders'], dfs.get('orders_last_year'))
        trend_df_bw, trend_df_m = get_dual_trend_data(dfs['orders'], dfs.get('orders_last_year'))

        st.success(f"âœ… æµ‹ç®—æˆåŠŸï¼æ•°æ®å‘¨æœŸ: {time_str}")
        
        # === 1. ç»è¥æ¦‚è§ˆ ===
        st.markdown("### ğŸ“ˆ 1. ç»è¥æ¦‚è§ˆ (KPI Dashboard)")
        kpi_col1, kpi_col2 = st.columns(2)
        
        with kpi_col1:
            st.markdown("""<div class="kpi-card"><div class="kpi-title">ğŸ“Š KPI è€ƒæ ¸ä¸è¿›åº¦</div>""", unsafe_allow_html=True)
            st.write(f"â³ æœˆåº¦æ—¶é—´è¿›åº¦ ({time_progress:.1%})")
            st.progress(time_progress)
            c1, c2 = st.columns(2)
            c1.metric("ğŸ¯ ç›®æ ‡è¥æ”¶", f"${target_revenue:,.0f}")
            c2.metric("ğŸ’° å®é™…è¥æ”¶", f"${curr_rev:,.0f}", f"{mtd_achieve:.1%} (è¾¾æˆç‡)")
            st.write(f"**è¿›åº¦åˆ¤å®š**: {pace_status} (MTD)")
            st.divider()
            c3, c4 = st.columns(2)
            c3.metric("ğŸ¯ ç›®æ ‡åˆ©æ¶¦ç‡", f"{target_profit_rate:.1%}")
            c4.metric("ğŸ’° å®é™…åˆ©æ¶¦ç‡", f"{shop_row['åˆ©æ¶¦ç‡']}", f"{(clean_money(shop_row['åˆ©æ¶¦ç‡'].strip('%'))/100 - target_profit_rate):.1%}")
            st.markdown("</div>", unsafe_allow_html=True)

        with kpi_col2:
            st.markdown("""<div class="kpi-card"><div class="kpi-title">ğŸŒ å¤§ç›˜æ ¸å¿ƒæ•°æ® (vs å»å¹´åŒæœŸ)</div>""", unsafe_allow_html=True)
            curr = yoy_data['curr']
            m1, m2 = st.columns(2)
            m1.metric("GMV (é€€æ¬¾å‰)", f"${shop_row['é€€æ¬¾å‰è¥æ”¶']:,.0f}")
            m2.metric("å‡€åˆ©æ¶¦", f"${shop_row['åˆ©æ¶¦é¢']:,.0f}")
            st.divider()
            m3, m4 = st.columns(2)
            m3.metric("ç»¼åˆé€€æ¬¾ç‡", shop_row['é€€æ¬¾ç‡'], "ç¾åŒºåŸºå‡† 10-20%", delta_color="inverse")
            m4.metric("è¥é”€è´¹æ¯”", shop_row['æ€»è¥é”€è´¹æ¯”'], "å«å¹¿å‘Š+è¾¾äºº+æ ·å“", delta_color="inverse")
            st.markdown("</div>", unsafe_allow_html=True)

        # === 2. è¶‹åŠ¿å›¾ ===
        st.markdown("### ğŸ“Š 2. è¥æ”¶è¶‹åŠ¿å¯¹æ¯”")
        t_tab1, t_tab2 = st.tabs(["ğŸ“… åŒå‘¨è§†å›¾ (Bi-Weekly)", "ğŸ—“ï¸ æœˆåº¦è§†å›¾ (Monthly)"])
        
        with t_tab1:
            if trend_df_bw is not None and not trend_df_bw.empty:
                chart = alt.Chart(trend_df_bw).mark_line(point=True).encode(
                    x=alt.X('X', title='åŒå‘¨å‘¨æœŸ'), y=alt.Y('Revenue', title='å‡€è¥æ”¶ ($)'),
                    color=alt.Color('Year', title='å¹´ä»½', scale=alt.Scale(domain=['ä»Šå¹´', 'å»å¹´'], range=['#ff0050', '#c3cfe2'])),
                    tooltip=['Year', 'X', 'Revenue']
                ).interactive()
                st.altair_chart(chart, use_container_width=True)
            else: st.info("æš‚æ— æ•°æ®")
            
        with t_tab2:
            if trend_df_m is not None and not trend_df_m.empty:
                chart = alt.Chart(trend_df_m).mark_line(point=True).encode(
                    x=alt.X('X', title='æœˆä»½'), y=alt.Y('Revenue', title='å‡€è¥æ”¶ ($)'),
                    color=alt.Color('Year', title='å¹´ä»½', scale=alt.Scale(domain=['ä»Šå¹´', 'å»å¹´'], range=['#ff0050', '#c3cfe2'])),
                    tooltip=['Year', 'X', 'Revenue']
                ).interactive()
                st.altair_chart(chart, use_container_width=True)
            else: st.info("æš‚æ— æ•°æ®")

        st.markdown("---")
        
        # === 3. çˆ†å“ä¸äºæŸ ===
        st.markdown("### ğŸ”¥ 3. çˆ†å“ä¸äºæŸåˆ†æ")
        col_p1, col_p2 = st.columns([1.5, 1])
        with col_p1:
            st.markdown("#### ğŸ† åˆ©æ¶¦è´¡çŒ® Top 10 SPU")
            if not df_spu.empty:
                df_spu_sort = df_spu.copy()
                df_spu_sort['åˆ©æ¶¦é¢'] = pd.to_numeric(df_spu_sort['åˆ©æ¶¦é¢'], errors='coerce')
                top_10 = df_spu_sort.sort_values(by='åˆ©æ¶¦é¢', ascending=False).head(10)
                chart_top = alt.Chart(top_10).mark_bar().encode(
                    x=alt.X('åˆ©æ¶¦é¢', title='å‡€åˆ©æ¶¦ ($)'), y=alt.Y('SPU', sort='-x'),
                    color=alt.value('#2ecc71'), tooltip=['SPU', 'åˆ©æ¶¦é¢', 'é”€é‡']
                ).interactive()
                st.altair_chart(chart_top, use_container_width=True)
        
        with col_p2:
            st.markdown("#### ğŸš¨ äºæŸè­¦ç¤ºæ¦œ (è´Ÿåˆ©æ¶¦)")
            if not df_spu.empty:
                df_spu_loss = df_spu.copy()
                df_spu_loss['åˆ©æ¶¦é¢'] = pd.to_numeric(df_spu_loss['åˆ©æ¶¦é¢'], errors='coerce')
                loss_spus = df_spu_loss[df_spu_loss['åˆ©æ¶¦é¢'] < 0].copy()
                if not loss_spus.empty:
                    loss_spus = loss_spus.sort_values(by='åˆ©æ¶¦é¢', ascending=True)
                    cols_loss = ['SPU', 'é”€é‡', 'é€€æ¬¾åè¥æ”¶', 'åˆ©æ¶¦é¢', 'åˆ©æ¶¦ç‡']
                    st.dataframe(loss_spus[cols_loss], use_container_width=True, height=400)
                else: st.success("ğŸ‰ æ­å–œï¼æœ¬æœŸæ²¡æœ‰äºæŸ SPUã€‚")

        st.markdown("---")
        
        # === 4. AI ä¸ æŠ¥è¡¨ ===
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ  åº—é“ºæ±‡æ€»", "ğŸ“¦ SPU åˆ†æ", "ğŸ“„ SKU æ˜ç»†", "ğŸ¤– AI ç»è¥å‚è°‹"])
        with tab1: st.dataframe(df_shop, use_container_width=True)
        with tab2: st.dataframe(df_spu, use_container_width=True)
        with tab3: st.dataframe(df_sku, use_container_width=True)
        
        with tab4:
            st.markdown("#### ğŸ§  AI æ™ºèƒ½ç»è¥åˆ†æ")
            st.info("ğŸ’¡ ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®ç”ŸæˆæŒ‡ä»¤ï¼Œå‘é€ç»™ ChatGPT/DeepSeekã€‚")
            if st.button("âœ¨ ç”Ÿæˆ AI åˆ†ææç¤ºè¯"):
                prompt = f"""
ä½ æ˜¯ä¸€åèµ„æ·±ç¾å›½ TikTok Shop ç”µå•†æ“ç›˜æ‰‹ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä¸šåŠ¡æ•°æ®ï¼Œæ’°å†™ä¸€ä»½ä¸“ä¸šçš„å‘¨æŠ¥åˆ†æã€‚

ã€1. KPI è€ƒæ ¸ä¸è¿›åº¦ã€‘
- æ—¥æœŸèŠ‚ç‚¹ï¼š{max_date.strftime('%Y-%m-%d') if pd.notna(max_date) else 'N/A'}
- æ—¶é—´è¿›åº¦ï¼š{time_progress:.1%}
- ç›®æ ‡è¥æ”¶ï¼š${target_revenue:,.0f} | å®é™…è¥æ”¶ï¼š${curr_rev:,.0f} | è¾¾æˆç‡ï¼š{mtd_achieve:.1%}
- è¿›åº¦åˆ¤å®šï¼š{pace_status}
- ç›®æ ‡åˆ©æ¶¦ç‡ï¼š{target_profit_rate:.1%} | å®é™…åˆ©æ¶¦ç‡ï¼š{shop_row['åˆ©æ¶¦ç‡']}

ã€2. å¤§ç›˜æ ¸å¿ƒæ•°æ®ã€‘
- GMVï¼š${shop_row['é€€æ¬¾å‰è¥æ”¶']:,.0f}
- å‡€åˆ©æ¶¦ï¼š${shop_row['åˆ©æ¶¦é¢']:,.0f}
- ç»¼åˆé€€æ¬¾ç‡ï¼š{shop_row['é€€æ¬¾ç‡']} (ç¾åŒºåŸºå‡†é€šå¸¸åœ¨ 10%-20%)
- è¥é”€è´¹æ¯”ï¼š{shop_row['æ€»è¥é”€è´¹æ¯”']} (å«å¹¿å‘Š+è¾¾äºº+æ ·å“)

ã€3. å¼‚å¸¸å•å“è¯Šæ–­ã€‘
[çº¢æ¦œ - åˆ©æ¶¦è´¡çŒ®å‰3]
{df_spu.head(3)[['SPU', 'åˆ©æ¶¦é¢', 'åˆ©æ¶¦ç‡']].to_string(index=False)}

[é»‘æ¦œ - äºæŸä¸¥é‡å‰3]
{df_spu.tail(3)[['SPU', 'åˆ©æ¶¦é¢', 'åˆ©æ¶¦ç‡', 'é€€æ¬¾ç‡', 'æ€»è¥é”€è´¹æ¯”']].to_string(index=False)}

ã€ä»»åŠ¡è¦æ±‚ã€‘
è¯·è¾“å‡ºä¸€ä»½ç»“æ„æ¸…æ™°çš„åˆ†ææŠ¥å‘Šï¼ŒåŒ…å«ï¼š
1. **ç»è¥æ‘˜è¦**ï¼šç‚¹è¯„æœ¬å‘¨ç›ˆäºåŠ KPI è¾¾æˆæƒ…å†µï¼Œè§£é‡Šä¸ºä½•{pace_status}ã€‚
2. **é—®é¢˜è¯Šæ–­**ï¼šåˆ†æäºæŸ SPU åŸå› ï¼ˆå¹¿å‘Šå¤±æ§ï¼Ÿé€€æ¬¾è¿‡é«˜ï¼Ÿå®šä»·å¤ªä½ï¼Ÿï¼‰ã€‚
3. **è¡ŒåŠ¨è®¡åˆ’**ï¼šç»™å‡º 3 æ¡å…·ä½“çš„ä¼˜åŒ–å»ºè®®ã€‚
"""
                st.code(prompt, language='text')
            
            report_content = st.text_area("âœï¸ åœ¨æ­¤ç²˜è´´ AI ç”Ÿæˆçš„æŠ¥å‘Šå¹¶ä¿®æ”¹...", height=400)
            if report_content:
                st.download_button("ğŸ“¥ å¯¼å‡ºæŠ¥å‘Š (.txt)", report_content, f"ç»è¥åˆ†æ_{time_str}.txt", "text/plain")

        # åº•éƒ¨ä¸‹è½½
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df_sku.to_excel(writer, sheet_name='SKUæ˜ç»†', index=False)
            df_spu.to_excel(writer, sheet_name='SPUæ±‡æ€»', index=False)
            df_shop.to_excel(writer, sheet_name='åº—é“ºæ±‡æ€»', index=False)
        st.download_button("ğŸ“¥ ä¸‹è½½å®Œæ•´ Excel åˆ©æ¶¦è¡¨", output.getvalue(), f"åˆ©æ¶¦è¡¨_{time_str}.xlsx")

if __name__ == '__main__':
    main()