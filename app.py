import streamlit as st
import pandas as pd
import numpy as np
import re
import altair as alt
import time
import os
from datetime import datetime

# ================= 1. é¡µé¢åŸºç¡€é…ç½® =================
st.set_page_config(
    page_title="TikTok AIè¿è¥ç³»ç»Ÿï¼ˆåˆ©æ¶¦&å¹¿å‘Š&è¾¾äººï¼‰",
    page_icon="ğŸ’°",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
    <style>
    .main {background-color: #f8f9fa;}
    div.stButton > button:first-child {
        background-color: #ff0050; color: white; border-radius: 8px;
        padding: 12px 24px; font-weight: 600; border: none; width: 100%; font-size: 18px;
    }
    div.stButton > button:first-child:hover {background-color: #d60043; color: white;}
    [data-testid="stMetricValue"] {font-size: 24px; font-weight: bold; color: #1e1e1e;}

    .kpi-card {
        background-color: white; padding: 18px; border-radius: 10px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05); margin-bottom: 16px; border: 1px solid #e0e0e0;
    }
    .kpi-title {font-size: 16px; color: #666; margin-bottom: 6px;}
    .note {color:#666; font-size: 12px;}
    .warn {color:#b04a00; font-size: 12px;}
    .ok {color:#117a37; font-size: 12px;}

    .stProgress > div > div > div > div {background-color: #ff0050;}
    </style>
""", unsafe_allow_html=True)

# ================= 2. å…¨å±€é…ç½® & æ ¸å¿ƒåˆ—åæ˜ å°„ =================
EXCHANGE_RATE = 1 / 7.15

# å¯è°ƒå‚æ•°ï¼ˆä¸šåŠ¡è§„åˆ™ï¼‰
ROI_BEST = 2.0
ROI_LOSS = 1.0
DEFAULT_ROAS_FOR_CPA_LINE = 3.0
COST_OBSERVE = 50.0

CTR_FLOOR = 0.01
CVR_FLOOR = 0.01
CPM_FLOOR_HIGH = 25.0

RATE2S_FLOOR = 0.20
RATE6S_FLOOR = 0.10

COLUMN_CONFIG = {
    'orders': {
        'sku': 'Seller SKU',
        'order_id': 'Order ID',
        'revenue': 'è¥æ”¶',
        'qty': 'Quantity',
        'status': 'Order Status',
        'time': 'Created Time',
        'product_name': 'Product Name'
    },
    'ads': {
        'pid': 'Product ID',
        'cost': 'Cost',
        'revenue': 'Gross revenue',
        'orders': 'SKU orders',
        'impressions': 'Product ad impressions',
        'clicks': 'Product ad clicks',
        'video_title': 'Video title',
        'video_id': 'Video ID',
        'ctr': 'Product ad click rate',
        'cvr': 'Ad conversion rate',
        'rate_2s': '2-second ad video view rate',
        'rate_6s': '6-second ad video view rate'
    },
    'affiliate': {
        'creator': 'Creator Username',
        'gmv': 'Payment Amount',
        'commission': 'Actual Commission Payment',
        'commission_est_std': 'Est. standard commission payment',
        'commission_est_ads': 'Est. Shop Ads commission payment',
        'content_type': 'Content Type',
        'order_id': 'Order ID',
        'sku': 'Seller Sku'
    },
    'transaction': {
        'pid': 'Product ID',
        'aff_gmv': 'Affiliate-attributed GMV',
        'videos': 'Videos',
        'lives': 'LIVE streams'
    }
}

TARGET_COLUMNS_SKU = [
    'SPU', 'SKU', 'ç±»åˆ«', 'é”€é‡', 'é€€æ¬¾å‰è¥æ”¶', 'é€€æ¬¾åè¥æ”¶',
    'åˆ©æ¶¦ç‡', 'åˆ©æ¶¦é¢', 'ASP', 'è¥ä¸šæˆæœ¬ç‡', 'è¿è¥æˆæœ¬ç‡', 'æ€»è¥é”€è´¹æ¯”',
    'å•ä»¶é‡‡è´­æˆæœ¬', 'å•ä»¶å¤´ç¨‹', 'å•ä»¶å…³ç¨', 'å•ä»¶å°¾ç¨‹',
    'é€€æ¬¾å•æ•°', 'é€€æ¬¾è¥æ”¶', 'é€€æ¬¾ç‡', 'æ€»è¾¾äººä½£é‡‘',
    'å•ä»¶æ ·å“æˆæœ¬', 'æ€»æ ·å“è´¹', 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹',
    'é‡‡è´­æˆæœ¬-å æ¯”', 'å¤´ç¨‹-å æ¯”', 'å…³ç¨å æ¯”', 'å°¾ç¨‹-å æ¯”',
    'ä»“ç§Ÿ-å æ¯”', 'å…¶ä»–ç‰©æµæˆæœ¬-å æ¯”', 'å“ç‰Œè´¹ç”¨-å æ¯”', 'å¹³å°ä½£é‡‘-å æ¯”',
    'å…¶ä»–å’Œå”®å-å æ¯”', 'è¾¾äººä½£é‡‘-å æ¯”', 'æ ·å“è´¹-å æ¯”', 'å¹¿å‘ŠæŠ•æ”¾è´¹-å æ¯”'
]
TARGET_COLUMNS_SPU = [col for col in TARGET_COLUMNS_SKU if col not in ['SKU', 'å•ä»¶é‡‡è´­æˆæœ¬', 'å•ä»¶å¤´ç¨‹', 'å•ä»¶å…³ç¨', 'å•ä»¶å°¾ç¨‹', 'å•ä»¶æ ·å“æˆæœ¬']]
TARGET_COLUMNS_SHOP = [col for col in TARGET_COLUMNS_SPU if col not in ['SPU', 'ç±»åˆ«']]
TARGET_COLUMNS_SHOP_FINAL = ['æ•°æ®å‘¨æœŸ'] + TARGET_COLUMNS_SHOP

# ================= 3. åŸºç¡€å·¥å…·å‡½æ•° =================
def normalize_headers(df):
    if df is None:
        return None
    df.columns = df.columns.astype(str).str.strip()
    return df

def clean_text(df, col_name):
    if col_name in df.columns:
        return df[col_name].astype(str).str.replace(r'[\u200b\ufeff]', '', regex=True).str.strip().str.upper()
    return df[col_name]

def convert_scientific_to_str(val):
    if pd.isna(val):
        return ""
    try:
        if isinstance(val, (int, float)):
            return str(int(val))
        s = str(val).strip()
        s = re.sub(r'[\u200b\ufeff]', '', s)
        if 'E' in s.upper():
            return str(int(float(s)))
        if s.endswith('.0'):
            return s[:-2]
        return s
    except:
        return str(val).strip()

def clean_money(val):
    if pd.isna(val):
        return 0.0
    s = str(val).strip()
    s = re.sub(r'[^\d\.\-]', '', s)
    try:
        return float(s)
    except:
        return 0.0

def clean_percent(val):
    if pd.isna(val):
        return 0.0
    s = str(val).strip().replace('%', '')
    try:
        return float(s) / 100.0
    except:
        return 0.0

def find_col_by_keyword_fuzzy(df, keywords):
    if df is None:
        return None
    for col in df.columns:
        c_low = str(col).lower()
        for k in keywords:
            if k in c_low:
                return col
    return None

def get_cost_map(cost_df, keywords):
    if cost_df is None:
        return {}
    target_col = find_col_by_keyword_fuzzy(cost_df, keywords)
    if not target_col:
        return {}
    sku_col = find_col_by_keyword_fuzzy(cost_df, ['sku'])
    if not sku_col:
        return {}
    cost_df = cost_df.copy()
    cost_df['SKU_Clean'] = cost_df[sku_col].astype(str).str.replace(r'[\u200b\ufeff]', '', regex=True).str.strip().str.upper()
    cost_df['Clean_Cost'] = cost_df[target_col].apply(clean_money)
    cost_df['USD'] = cost_df['Clean_Cost'] * EXCHANGE_RATE
    return dict(zip(cost_df['SKU_Clean'], cost_df['USD']))

def build_sku_to_spu_dict(df_spu_sku):
    if df_spu_sku is None:
        return {}
    mapping_dict = {}
    spu_col = find_col_by_keyword_fuzzy(df_spu_sku, ['spu'])
    if not spu_col:
        return {}
    candidate_cols = [c for c in df_spu_sku.columns if 'sku' in str(c).lower() and c != spu_col]
    for _, row in df_spu_sku.iterrows():
        target_spu = row[spu_col]
        if pd.isna(target_spu) or str(target_spu).strip() == '':
            continue
        target_spu = str(target_spu).strip()
        for col in candidate_cols:
            sku_val = row[col]
            if pd.notna(sku_val) and str(sku_val).strip() != '':
                mapping_dict[str(sku_val).strip().upper()] = target_spu
    return mapping_dict

def format_dataframe(df, target_columns):
    df_out = df.copy()
    for col in target_columns:
        if col not in df_out.columns:
            df_out[col] = 0
    df_out = df_out.reindex(columns=target_columns, fill_value=0)

    numeric_cols = df_out.select_dtypes(include=[np.number]).columns
    money_cols = [c for c in numeric_cols if 'å æ¯”' not in c and 'ç‡' not in c and 'ASP' not in c]
    df_out[money_cols] = df_out[money_cols].fillna(0).round(2)

    for col in df_out.columns:
        if 'å æ¯”' in col or 'ç‡' in col:
            df_out[col] = df_out[col].fillna(0).apply(lambda x: f"{x:.2%}")
    return df_out

def safe_div(a, b, default=0.0):
    try:
        return a / b if b not in [0, 0.0, None, np.nan] else default
    except:
        return default

# ================= 4. æ—¥æœŸå¤„ç† =================
def ensure_date_column(df):
    if df is None or df.empty:
        return False
    if 'Date' in df.columns:
        return True
    col_date = None
    for c in df.columns:
        if 'created time' in c.lower() or 'time posted' in c.lower():
            col_date = c
            break
    if col_date:
        try:
            df['Date'] = pd.to_datetime(df[col_date], dayfirst=False, errors='coerce')
            return df['Date'].notna().any()
        except:
            return False
    return False

def get_dual_trend_data(df_curr, df_last):
    if df_curr is None:
        return None, None
    ensure_date_column(df_curr)
    cols = ['X', 'Revenue', 'Year']
    data_biweek = []
    data_monthly = []

    rev_col_name = COLUMN_CONFIG['orders']['revenue']

    def process_df(df, year_label):
        if 'Date' not in df.columns:
            return
        col_rev = None
        for c in df.columns:
            if rev_col_name in c or 'revenue' in c.lower() or 'amount' in c.lower():
                col_rev = c
                break
        if not col_rev:
            return
        df = df.copy()
        df[col_rev] = pd.to_numeric(df[col_rev], errors='coerce').fillna(0)

        col_status = None
        for c in df.columns:
            if 'status' in c.lower():
                col_status = c
                break
        if col_status:
            is_can = df[col_status].astype(str).str.strip().isin(['Cancelled', 'Canceled'])
            df_clean = df[~is_can].copy()
        else:
            df_clean = df.copy()

        df_clean['Month'] = df_clean['Date'].dt.strftime('%m')
        monthly_agg = df_clean.groupby('Month')[col_rev].sum().reset_index()
        for _, row in monthly_agg.iterrows():
            data_monthly.append({'X': row['Month'], 'Revenue': row[col_rev], 'Year': year_label})

        df_clean['DayOfYear'] = df_clean['Date'].dt.dayofyear
        df_clean['BiWeek'] = (df_clean['DayOfYear'] - 1) // 14 + 1
        biweek_agg = df_clean.groupby('BiWeek')[col_rev].sum().reset_index()
        for _, row in biweek_agg.iterrows():
            label = f"Bi-Week {int(row['BiWeek']):02d}"
            data_biweek.append({'X': label, 'Revenue': row[col_rev], 'Year': year_label})

    process_df(df_curr, 'ä»Šå¹´')
    if df_last is not None and ensure_date_column(df_last):
        process_df(df_last, 'å»å¹´')

    df_bw = pd.DataFrame(data_biweek, columns=cols) if data_biweek else pd.DataFrame(columns=cols)
    df_m = pd.DataFrame(data_monthly, columns=cols) if data_monthly else pd.DataFrame(columns=cols)
    return df_bw, df_m

# ================= 5. æ ¸å¿ƒåˆ©æ¶¦è®¡ç®— =================
def calculate_metrics_final(df_base):
    df = df_base.copy()
    qty = df['é”€é‡'].replace(0, 1)
    rev_after = df['é€€æ¬¾åè¥æ”¶']
    df['ASP'] = rev_after / qty

    if 'Refund_Orders' not in df.columns:
        df['Refund_Orders'] = 0

    df['é€€æ¬¾è¥æ”¶'] = df['Refund_Orders'] * df['ASP']
    df['é€€æ¬¾å‰è¥æ”¶'] = rev_after + df['é€€æ¬¾è¥æ”¶']

    rev_before_safe = df['é€€æ¬¾å‰è¥æ”¶'].replace(0, 1)
    df['é€€æ¬¾ç‡'] = df['é€€æ¬¾è¥æ”¶'] / rev_before_safe
    df['é€€æ¬¾å•æ•°'] = df['Refund_Orders']

    for c in ['æ€»è¾¾äººä½£é‡‘', 'æ€»æ ·å“è´¹', 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹', 'é‡‡è´­æˆæœ¬', 'å¤´ç¨‹', 'å°¾ç¨‹', 'å…³ç¨']:
        if c not in df.columns:
            df[c] = 0
        else:
            df[c] = df[c].fillna(0)

    mkt_cost = df['æ€»å¹¿å‘ŠæŠ•æ”¾è´¹'] + df['æ€»è¾¾äººä½£é‡‘'] + df['æ€»æ ·å“è´¹']
    df['æ€»è¥é”€è´¹æ¯”'] = mkt_cost / rev_after.replace(0, 1)

    # è¿è¥æˆæœ¬ï¼ˆæŒ‰è¥æ”¶æ¯”ä¾‹ä¼°ç®—ï¼‰
    df['ä»“ç§Ÿ'] = rev_after * 0.005
    df['å…¶ä»–ç‰©æµæˆæœ¬'] = rev_after * 0.003
    df['å“ç‰Œè´¹ç”¨'] = rev_after * 0.003
    df['å¹³å°ä½£é‡‘'] = rev_after * 0.06
    df['å…¶ä»–å’Œå”®å'] = rev_after * 0.003

    all_costs = sum(df[c] for c in [
        'é‡‡è´­æˆæœ¬', 'å¤´ç¨‹', 'å°¾ç¨‹', 'å…³ç¨',
        'ä»“ç§Ÿ', 'å…¶ä»–ç‰©æµæˆæœ¬', 'å“ç‰Œè´¹ç”¨', 'å¹³å°ä½£é‡‘', 'å…¶ä»–å’Œå”®å',
        'æ€»è¾¾äººä½£é‡‘', 'æ€»æ ·å“è´¹', 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹'
    ])
    df['åˆ©æ¶¦é¢'] = rev_after - all_costs
    df['åˆ©æ¶¦ç‡'] = df['åˆ©æ¶¦é¢'] / rev_after.replace(0, 1)

    rev_safe = rev_after.replace(0, 1)
    cogs = df['é‡‡è´­æˆæœ¬'] + df['å¤´ç¨‹'] + df['å…³ç¨'] + df['å°¾ç¨‹']
    df['è¥ä¸šæˆæœ¬ç‡'] = cogs / rev_safe
    ops_cost = df['ä»“ç§Ÿ'] + df['å…¶ä»–ç‰©æµæˆæœ¬'] + df['å“ç‰Œè´¹ç”¨'] + df['å¹³å°ä½£é‡‘'] + df['å…¶ä»–å’Œå”®å']
    df['è¿è¥æˆæœ¬ç‡'] = ops_cost / rev_safe

    ratio_map = {
        'é‡‡è´­æˆæœ¬-å æ¯”': 'é‡‡è´­æˆæœ¬', 'å¤´ç¨‹-å æ¯”': 'å¤´ç¨‹', 'å°¾ç¨‹-å æ¯”': 'å°¾ç¨‹', 'å…³ç¨å æ¯”': 'å…³ç¨',
        'ä»“ç§Ÿ-å æ¯”': 'ä»“ç§Ÿ', 'å…¶ä»–ç‰©æµæˆæœ¬-å æ¯”': 'å…¶ä»–ç‰©æµæˆæœ¬',
        'å“ç‰Œè´¹ç”¨-å æ¯”': 'å“ç‰Œè´¹ç”¨', 'å¹³å°ä½£é‡‘-å æ¯”': 'å¹³å°ä½£é‡‘', 'å…¶ä»–å’Œå”®å-å æ¯”': 'å…¶ä»–å’Œå”®å',
        'è¾¾äººä½£é‡‘-å æ¯”': 'æ€»è¾¾äººä½£é‡‘', 'æ ·å“è´¹-å æ¯”': 'æ€»æ ·å“è´¹', 'å¹¿å‘ŠæŠ•æ”¾è´¹-å æ¯”': 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹',
    }
    for r_col, val_col in ratio_map.items():
        df[r_col] = df[val_col] / rev_safe if val_col in df.columns else 0

    return df

# ================= 6. å¹¿å‘Šåˆ†æï¼ˆV2 ä¸¤å±‚è¯Šæ–­ï¼‰ =================
def process_ads_data_v2(dfs, df_sku_final):
    df_ads = dfs.get('ads')
    df_mapping = dfs.get('mapping')
    df_spu_sku = dfs.get('spu_sku')

    if df_ads is None:
        return None, None, None, {}

    # Required columns
    col_pid = COLUMN_CONFIG['ads']['pid']
    col_cost = COLUMN_CONFIG['ads']['cost']
    col_rev = COLUMN_CONFIG['ads']['revenue']
    col_orders = COLUMN_CONFIG['ads']['orders']
    col_imp = COLUMN_CONFIG['ads']['impressions']
    col_clicks = COLUMN_CONFIG['ads']['clicks']
    col_video = COLUMN_CONFIG['ads']['video_title']

    required = [col_pid, col_cost, col_rev, col_orders, col_imp, col_clicks, col_video]
    if any(c not in df_ads.columns for c in required):
        return None, None, None, {"error": f"å¹¿å‘Šè¡¨ç¼ºå°‘å¿…è¦åˆ—ï¼š{[c for c in required if c not in df_ads.columns]}"}

    df_ads = df_ads.copy()
    df_ads['PID_Clean'] = clean_text(df_ads, col_pid)
    df_ads['Cost_Val'] = df_ads[col_cost].apply(clean_money)
    df_ads['Rev_Val'] = df_ads[col_rev].apply(clean_money)
    df_ads['Ord_Val'] = df_ads[col_orders].apply(clean_money)
    df_ads['Imp_Val'] = df_ads[col_imp].apply(clean_money)
    df_ads['Clk_Val'] = df_ads[col_clicks].apply(clean_money)
    df_ads['Vid_Title'] = clean_text(df_ads, col_video)

    # Rates: if exist use, else compute
    # CTR
    c_ctr = COLUMN_CONFIG['ads']['ctr']
    if c_ctr in df_ads.columns:
        df_ads['CTR'] = df_ads[c_ctr].apply(clean_percent)
    else:
        df_ads['CTR'] = df_ads.apply(lambda x: (x['Clk_Val'] / x['Imp_Val']) if x['Imp_Val'] > 0 else 0.0, axis=1)

    # CVR
    c_cvr = COLUMN_CONFIG['ads']['cvr']
    if c_cvr in df_ads.columns:
        df_ads['CVR'] = df_ads[c_cvr].apply(clean_percent)
    else:
        df_ads['CVR'] = df_ads.apply(lambda x: (x['Ord_Val'] / x['Clk_Val']) if x['Clk_Val'] > 0 else 0.0, axis=1)

    # 2s/6s rates
    c_2s = COLUMN_CONFIG['ads']['rate_2s']
    c_6s = COLUMN_CONFIG['ads']['rate_6s']
    df_ads['RATE_2S'] = df_ads[c_2s].apply(clean_percent) if c_2s in df_ads.columns else 0.0
    df_ads['RATE_6S'] = df_ads[c_6s].apply(clean_percent) if c_6s in df_ads.columns else 0.0

    # Build mapping: PID -> SKUs, SKU -> SPU
    pid_skus_map = {}
    if df_mapping is not None:
        df_mapping = df_mapping.copy()
        m_pid = find_col_by_keyword_fuzzy(df_mapping, ['product_id'])
        m_sku = find_col_by_keyword_fuzzy(df_mapping, ['sku'])
        if m_pid and m_sku:
            df_mapping['PID_Clean'] = clean_text(df_mapping, m_pid)
            df_mapping['SKU_Clean'] = clean_text(df_mapping, m_sku)
            pid_skus_map = df_mapping.groupby('PID_Clean')['SKU_Clean'].apply(lambda x: list(sorted(set(x.tolist())))).to_dict()

    sku_spu_map = build_sku_to_spu_dict(df_spu_sku) if df_spu_sku is not None else {}

    def pid_to_spu_str(pid):
        skus = pid_skus_map.get(pid, [])
        if not skus:
            return "æœªåŒ¹é…"
        spus = sorted(list(set(sku_spu_map.get(s, s) for s in skus)))
        return ", ".join(spus) if spus else "æœªåŒ¹é…"

    # âœ… æ–°å¢ï¼šå¹¿å‘Šæ˜ç»†è¡Œä¹Ÿå¸¦ä¸Š SPUï¼ˆç”¨äº video æ˜ å°„ï¼‰
    df_ads['SPU'] = df_ads['PID_Clean'].apply(pid_to_spu_str)

    # Prepare SKU margin map for CPA_Line (AUTO)
    sku_margin_map = {}
    sku_rev_weight_map = {}
    if df_sku_final is not None and not df_sku_final.empty:
        tmp = df_sku_final.copy()
        # Need: SKU, ASP, è¿è¥æˆæœ¬ç‡, å•ä»¶é‡‡è´­æˆæœ¬, å•ä»¶å¤´ç¨‹, å•ä»¶å°¾ç¨‹, å•ä»¶å…³ç¨(å¯é€‰), é€€æ¬¾åè¥æ”¶(ç”¨ä½œæƒé‡)
        for _, r in tmp.iterrows():
            sku = str(r.get('SKU', '')).strip().upper()
            if not sku:
                continue
            asp = float(r.get('ASP', 0) or 0)
            var_rate = float(r.get('è¿è¥æˆæœ¬ç‡', 0) or 0)
            fixed = float(r.get('å•ä»¶é‡‡è´­æˆæœ¬', 0) or 0) + float(r.get('å•ä»¶å¤´ç¨‹', 0) or 0) + float(r.get('å•ä»¶å°¾ç¨‹', 0) or 0)
            fixed += float(r.get('å•ä»¶å…³ç¨', 0) or 0)
            margin = asp - (fixed + asp * var_rate)
            sku_margin_map[sku] = margin
            sku_rev_weight_map[sku] = float(r.get('é€€æ¬¾åè¥æ”¶', 0) or 0)

    def compute_cpa_line(pid, aov):
        skus = pid_skus_map.get(pid, [])
        if skus and sku_margin_map:
            margins = []
            weights = []
            for s in skus:
                s2 = str(s).strip().upper()
                if s2 in sku_margin_map:
                    margins.append(sku_margin_map[s2])
                    weights.append(max(sku_rev_weight_map.get(s2, 0.0), 0.0))
            if margins:
                wsum = sum(weights)
                if wsum > 0:
                    return float(np.average(margins, weights=weights)), "AUTO"
                return float(np.mean(margins)), "AUTO"
        # DEFAULT
        return (aov / DEFAULT_ROAS_FOR_CPA_LINE) if aov > 0 else 0.0, "DEFAULT"

    # Aggregate to PID level
    df_prod = df_ads.groupby('PID_Clean').agg({
        'Cost_Val': 'sum',
        'Rev_Val': 'sum',
        'Ord_Val': 'sum',
        'Imp_Val': 'sum',
        'Clk_Val': 'sum'
    }).reset_index()

    df_prod.rename(columns={
        'PID_Clean': 'Product ID',
        'Cost_Val': 'Cost',
        'Rev_Val': 'Revenue',
        'Ord_Val': 'Orders'
    }, inplace=True)

    # Derived metrics
    df_prod['ROI'] = df_prod.apply(lambda x: (x['Revenue'] / x['Cost']) if x['Cost'] > 0 else 0.0, axis=1)
    df_prod['CPA'] = df_prod.apply(lambda x: (x['Cost'] / x['Orders']) if x['Orders'] > 0 else 0.0, axis=1)
    df_prod['CPM'] = df_prod.apply(lambda x: (x['Cost'] / x['Imp_Val'] * 1000) if x['Imp_Val'] > 0 else 0.0, axis=1)
    df_prod['CTR'] = df_prod.apply(lambda x: (x['Clk_Val'] / x['Imp_Val']) if x['Imp_Val'] > 0 else 0.0, axis=1)
    df_prod['CVR'] = df_prod.apply(lambda x: (x['Orders'] / x['Clk_Val']) if x['Clk_Val'] > 0 else 0.0, axis=1)
    df_prod['AOV'] = df_prod.apply(lambda x: (x['Revenue'] / x['Orders']) if x['Orders'] > 0 else 0.0, axis=1)

    df_prod['SPU'] = df_prod['Product ID'].apply(pid_to_spu_str)

    # Compute CPA_Line + source
    cpa_lines = []
    sources = []
    for _, r in df_prod.iterrows():
        line, src = compute_cpa_line(r['Product ID'], r['AOV'])
        cpa_lines.append(line)
        sources.append(src)
    df_prod['CPA_Line'] = cpa_lines
    df_prod['CPA_Line_Source'] = sources

    # Global thresholds (dynamic + floor)
    med_ctr = float(df_prod['CTR'].median()) if not df_prod.empty else CTR_FLOOR
    med_cvr = float(df_prod['CVR'].median()) if not df_prod.empty else CVR_FLOOR
    med_cpm = float(df_prod['CPM'].median()) if not df_prod.empty else CPM_FLOOR_HIGH

    thr_ctr_low = max(med_ctr, CTR_FLOOR)
    thr_cvr_low = max(med_cvr, CVR_FLOOR)
    thr_cpm_high = max(med_cpm, CPM_FLOOR_HIGH)

    def pid_status_and_diag(row):
        if row['Cost'] < COST_OBSERVE:
            return "âšª è§‚å¯ŸæœŸ", "èŠ±è´¹å¤ªå°‘ï¼Œç»§ç»­è§‚å¯Ÿ", "ç»§ç»­æµ‹/å…ˆåˆ«ä¸‹ç»“è®º"
        # çˆ†æ¬¾
        if (row['ROI'] > ROI_BEST) and (row['CPA_Line'] > 0) and (row['CPA'] < row['CPA_Line']):
            return "ğŸŸ¢ çˆ†æ¬¾", "ç›ˆåˆ©ä¸”èµ·é‡", "å»ºè®®æ‰©é‡ï¼ˆåŠ é¢„ç®—/å¤åˆ¶å—ä¼—/å¤åˆ¶ç´ æï¼‰"
        # äºæŸ
        is_loss = (row['ROI'] < ROI_LOSS) or ((row['CPA_Line'] > 0) and (row['CPA'] > row['CPA_Line']))
        if is_loss:
            # åˆ†å‰è¯Šæ–­ä¼˜å…ˆçº§ï¼šCVRä½ -> CPMé«˜ -> CTRä½
            if row['CVR'] < thr_cvr_low:
                return "ğŸ”´ äºæŸ", "CVR ä½ï¼šæµé‡æ¥äº†æ¥ä¸ä½", "æ£€æŸ¥äº§å“/ä»·æ ¼/è½åœ°é¡µ/è´§ä¸å¯¹æ¿"
            if row['CPM'] > thr_cpm_high:
                return "ğŸ”´ äºæŸ", "CPM é«˜ï¼šæµé‡å¤ªè´µ", "è°ƒæ•´å—ä¼—/å‡ºæ–°ç´ æ/é¿å¼€é«˜ç«äº‰æ—¶æ®µ"
            if row['CTR'] < thr_ctr_low:
                return "ğŸ”´ äºæŸ", "CTR ä½ï¼šæ²¡äººç‚¹", "ä¼˜åŒ–å°é¢ä¸å¼€å¤´3ç§’ï¼ˆé’©å­/å¯¹æ¯”/è¯æ®ï¼‰"
            return "ğŸ”´ äºæŸ", "ç»¼åˆåä½ï¼šROIä¸è¾¾æ ‡", "ä¼˜å…ˆæ”¹ç´ æä¸å•†å“é¡µè¡¨è¾¾"
        # ç°åŒº
        return "ğŸŸ¡ å¯ä¼˜åŒ–", "æ¥è¿‘ç›ˆäºçº¿", "æŒ‰ CTR/CVR/CPM æœ€å¼±é¡¹ä¼˜åŒ–åç»§ç»­æµ‹"

    df_prod[['Status', 'Diagnosis', 'Action']] = df_prod.apply(lambda x: pd.Series(pid_status_and_diag(x)), axis=1)

    # âœ… éœ€æ±‚2ï¼šäº§å“ç›ˆäºè¯Šæ–­è¡¨æ ¼ä¸­ SPU åˆ—æ”¾åˆ° Product ID å·¦ä¾§ï¼ˆåªè°ƒé¡ºåºï¼Œä¸æ”¹æ•°æ®ï¼‰
    if 'SPU' in df_prod.columns and 'Product ID' in df_prod.columns:
        cols = df_prod.columns.tolist()
        new_cols = []
        for c in cols:
            if c not in ['SPU', 'Product ID']:
                new_cols.append(c)
        df_prod = df_prod[['SPU', 'Product ID'] + new_cols]

    # Video level aggregation
    df_video = df_ads.groupby('Vid_Title').agg({
        'Cost_Val': 'sum',
        'Rev_Val': 'sum',
        'Imp_Val': 'sum',
        'Clk_Val': 'sum',
        'Ord_Val': 'sum',
        'CTR': 'mean',
        'CVR': 'mean',
        'RATE_2S': 'mean',
        'RATE_6S': 'mean'
    }).reset_index()

    df_video.rename(columns={
        'Vid_Title': 'Video title',
        'Cost_Val': 'Cost',
        'Rev_Val': 'Revenue',
        'Ord_Val': 'Orders'
    }, inplace=True)

    df_video['ROI'] = df_video.apply(lambda x: (x['Revenue'] / x['Cost']) if x['Cost'] > 0 else 0.0, axis=1)

    # âœ… éœ€æ±‚3ï¼švideo title å·¦ä¾§å¢åŠ  SPU + Product IDï¼ˆä»æ˜ç»†é‡Œå–â€œæœ€å¸¸å‡ºç°çš„â€æ˜ å°„ï¼‰
    title_to_pid = df_ads.groupby('Vid_Title')['PID_Clean'].agg(lambda x: x.value_counts().idxmax() if len(x) else "").to_dict()
    title_to_spu = df_ads.groupby('Vid_Title')['SPU'].agg(lambda x: x.value_counts().idxmax() if len(x) else "æœªåŒ¹é…").to_dict()
    df_video['Product ID'] = df_video['Video title'].map(lambda t: title_to_pid.get(str(t).strip().upper(), ""))
    df_video['SPU'] = df_video['Video title'].map(lambda t: title_to_spu.get(str(t).strip().upper(), "æœªåŒ¹é…"))

    # Dynamic thresholds for video
    med_v_ctr = float(df_video['CTR'].median()) if not df_video.empty else CTR_FLOOR
    med_v_cvr = float(df_video['CVR'].median()) if not df_video.empty else CVR_FLOOR
    med_v_2s = float(df_video['RATE_2S'].median()) if not df_video.empty else RATE2S_FLOOR
    med_v_6s = float(df_video['RATE_6S'].median()) if not df_video.empty else RATE6S_FLOOR

    thr_v_ctr_high = max(med_v_ctr, CTR_FLOOR)
    thr_v_cvr_high = max(med_v_cvr, CVR_FLOOR)
    thr_v_2s_high = max(med_v_2s, RATE2S_FLOOR)
    # 6s ä½ï¼šæŒ‰â€œä½äºä¸­ä½æ•°ä¸”ä½äºåº•çº¿â€æ›´ä¸¥æ ¼ï¼Œè¿™é‡Œå–äºŒè€…æ›´å°ä½œä¸ºä½é˜ˆå€¼
    thr_v_6s_low = min(med_v_6s, RATE6S_FLOOR)
    thr_v_cvr_low = max(med_v_cvr, CVR_FLOOR)

    # âœ… éœ€æ±‚5ï¼šAIç»“è®ºç»™å‡ºå…·ä½“åˆ¤æ–­æ ‡å‡†
    def classify_video(row):
        ctr = row.get('CTR', 0.0)
        cvr = row.get('CVR', 0.0)
        r2 = row.get('RATE_2S', 0.0)
        r6 = row.get('RATE_6S', 0.0)

        # é»„é‡‘ï¼šé«˜CTR + é«˜2s + é«˜CVR
        if (ctr >= thr_v_ctr_high) and (r2 >= thr_v_2s_high) and (cvr >= thr_v_cvr_high):
            standard = f"æ ‡å‡†ï¼šCTRâ‰¥{thr_v_ctr_high:.2%} ä¸” 2sâ‰¥{thr_v_2s_high:.2%} ä¸” CVRâ‰¥{thr_v_cvr_high:.2%}"
            return "ğŸ¥‡ é»„é‡‘ç´ æ", f"{standard}ï¼ˆå¼€å¤´å¸ç›+å†…å®¹æ‰¿æ¥+è½¬åŒ–ç²¾å‡†ï¼‰", "å¤åˆ¶ç»“æ„/å¼€å¤´å¥—è·¯ï¼Œæ‰©é‡æŠ•æ”¾"

        # æ ‡é¢˜å…šï¼šé«˜CTR + ä½6s
        if (ctr >= thr_v_ctr_high) and (r6 <= thr_v_6s_low):
            standard = f"æ ‡å‡†ï¼šCTRâ‰¥{thr_v_ctr_high:.2%} ä¸” 6sâ‰¤{thr_v_6s_low:.2%}"
            return "ğŸ£ æ ‡é¢˜å…š", f"{standard}ï¼ˆéª—ç‚¹å‡»ï¼Œå†…å®¹å´©å¡Œï¼Œç”¨æˆ·6ç§’å†…å¤§é‡æµå¤±ï¼‰", "é‡å‰ªå‰6ç§’æ‰¿æ¥ï¼Œå–ç‚¹å‰ç½®"

        # æ— æ•ˆç§è‰ï¼šé«˜å®Œæ’­ï¼ˆ2sæˆ–6sé«˜ï¼‰ + ä½CVR
        if ((r2 >= thr_v_2s_high) or (r6 >= max(med_v_6s, RATE6S_FLOOR))) and (cvr < thr_v_cvr_low):
            standard = f"æ ‡å‡†ï¼š2sâ‰¥{thr_v_2s_high:.2%} æˆ– 6sâ‰¥{max(med_v_6s, RATE6S_FLOOR):.2%} ä¸” CVR<{thr_v_cvr_low:.2%}"
            return "ğŸŒ¿ æ— æ•ˆç§è‰", f"{standard}ï¼ˆå¥½çœ‹ä½†ä¸å–è´§/è´§ä¸å¯¹æ¿/ç¼ºè¯æ®é•œå¤´ï¼‰", "å¼ºåŒ–è´­ä¹°ç†ç”±/è¯æ®é•œå¤´/å•†å“é¡µä¸€è‡´æ€§"

        standard = "æ ‡å‡†ï¼šä¸æ»¡è¶³é»„é‡‘/æ ‡é¢˜å…š/æ— æ•ˆç§è‰ï¼ˆä¸‰ç±»ï¼‰æˆ–æ ·æœ¬ä¸è¶³"
        return "ğŸ—‘ï¸ å…¶ä»–", standard, "ç»§ç»­æµ‹è¯•æˆ–å½’æ¡£"

    df_video[['Creative Type', 'AI_Conclusion', 'Next_Action']] = df_video.apply(lambda x: pd.Series(classify_video(x)), axis=1)

    # Hook vs Pitch matrix fields (for plotting)
    df_video['HookRate_2S'] = df_video['RATE_2S']

    # âœ… éœ€æ±‚3ï¼šæŠŠåˆ—é¡ºåºæ”¹æˆ SPUã€Product IDã€Video title åœ¨æœ€å·¦ä¾§
    if ('SPU' in df_video.columns) and ('Product ID' in df_video.columns) and ('Video title' in df_video.columns):
        vcols = df_video.columns.tolist()
        rest = [c for c in vcols if c not in ['SPU', 'Product ID', 'Video title']]
        df_video = df_video[['SPU', 'Product ID', 'Video title'] + rest]

    meta = {
        "thr_prod": {"CTR_low": thr_ctr_low, "CVR_low": thr_cvr_low, "CPM_high": thr_cpm_high},
        "thr_video": {
            "CTR_high": thr_v_ctr_high, "CVR_high": thr_v_cvr_high,
            "RATE2S_high": thr_v_2s_high, "RATE6S_low": thr_v_6s_low
        },
        "no_daily": True
    }

    # Return raw detail ads df also
    return df_prod, df_video, df_ads, meta

# ================= 7. è¾¾äººåˆ†æï¼ˆV2ï¼‰ =================
def process_creator_data_v2(dfs, df_shop_raw, df_spu_raw):
    df_aff = dfs.get('affiliate')
    df_trans = dfs.get('transaction')
    res = {
        "overall": None,
        "leaderboard": None,
        "content_pie": None,
        "spu_perf": None,
        "commission_source_note": ""
    }

    # ---------- Overall & SPU performance from Transaction ----------
    if df_trans is not None:
        c_pid = COLUMN_CONFIG['transaction']['pid']
        c_aff_gmv = COLUMN_CONFIG['transaction']['aff_gmv']
        c_videos = COLUMN_CONFIG['transaction']['videos']
        c_lives = COLUMN_CONFIG['transaction']['lives']

        if c_pid in df_trans.columns and c_aff_gmv in df_trans.columns:
            df_trans = df_trans.copy()
            df_trans['PID_Clean'] = clean_text(df_trans, c_pid)
            df_trans['Affiliate_GMV'] = df_trans[c_aff_gmv].apply(clean_money)
            df_trans['Videos'] = pd.to_numeric(df_trans.get(c_videos, 0), errors='coerce').fillna(0)
            df_trans['Lives'] = pd.to_numeric(df_trans.get(c_lives, 0), errors='coerce').fillna(0)

            # Map PID -> SPU (first match)
            df_mapping = dfs.get('mapping')
            df_spu_sku = dfs.get('spu_sku')
            pid_skus_map = {}
            sku_spu_map = build_sku_to_spu_dict(df_spu_sku) if df_spu_sku is not None else {}

            if df_mapping is not None:
                df_mapping = df_mapping.copy()
                m_pid = find_col_by_keyword_fuzzy(df_mapping, ['product_id'])
                m_sku = find_col_by_keyword_fuzzy(df_mapping, ['sku'])
                if m_pid and m_sku:
                    df_mapping['PID_Clean'] = clean_text(df_mapping, m_pid)
                    df_mapping['SKU_Clean'] = clean_text(df_mapping, m_sku)
                    pid_skus_map = df_mapping.groupby('PID_Clean')['SKU_Clean'].apply(lambda x: list(sorted(set(x.tolist())))).to_dict()

            def get_spu(pid):
                skus = pid_skus_map.get(pid, [])
                spus = [sku_spu_map.get(s, s) for s in skus]
                return spus[0] if spus else "æœªåŒ¹é…"

            df_trans['SPU'] = df_trans['PID_Clean'].apply(get_spu)

            spu_aff = df_trans.groupby('SPU').agg({
                'Affiliate_GMV': 'sum',
                'Videos': 'sum',
                'Lives': 'sum'
            }).reset_index()

            # Shop GMV before (refund-before) as denominator
            shop_gmv_before = 0.0
            if df_shop_raw is not None and not df_shop_raw.empty and 'é€€æ¬¾å‰è¥æ”¶' in df_shop_raw.columns:
                shop_gmv_before = float(df_shop_raw.iloc[0]['é€€æ¬¾å‰è¥æ”¶'] or 0)

            # Overall achievement (shop level)
            aff_gmv_shop = float(df_trans['Affiliate_GMV'].sum())
            videos_shop = float(df_trans['Videos'].sum())
            res['overall'] = {
                "Affiliate_GMV": aff_gmv_shop,
                "Affiliate_Share": (aff_gmv_shop / shop_gmv_before) if shop_gmv_before > 0 else 0.0,
                "Videos": videos_shop,
                "Efficiency": (aff_gmv_shop / videos_shop) if videos_shop > 0 else 0.0
            }

            # SPU denominators from df_spu_raw (refund-before GMV)
            shop_gmv_map = {}
            if df_spu_raw is not None and not df_spu_raw.empty:
                if 'é€€æ¬¾å‰è¥æ”¶' in df_spu_raw.columns:
                    shop_gmv_map = dict(zip(df_spu_raw['SPU'], df_spu_raw['é€€æ¬¾å‰è¥æ”¶']))
                else:
                    shop_gmv_map = dict(zip(df_spu_raw['SPU'], df_spu_raw.get('é€€æ¬¾åè¥æ”¶', 0)))

            spu_aff['Shop_GMV_Before'] = spu_aff['SPU'].map(shop_gmv_map).fillna(0.0)
            spu_aff['Affiliate_Rate'] = spu_aff.apply(lambda x: (x['Affiliate_GMV'] / x['Shop_GMV_Before']) if x['Shop_GMV_Before'] > 0 else 0.0, axis=1)
            spu_aff['OutputPerVideo'] = spu_aff.apply(lambda x: (x['Affiliate_GMV'] / x['Videos']) if x['Videos'] > 0 else 0.0, axis=1)

            res['spu_perf'] = spu_aff.sort_values('Affiliate_GMV', ascending=False)

    # ---------- Leaderboard & content type pie from Affiliate ----------
    if df_aff is not None:
        c_name = COLUMN_CONFIG['affiliate']['creator']
        c_gmv = COLUMN_CONFIG['affiliate']['gmv']
        c_type = COLUMN_CONFIG['affiliate']['content_type']

        c_est_std = COLUMN_CONFIG['affiliate']['commission_est_std']
        c_est_ads = COLUMN_CONFIG['affiliate']['commission_est_ads']
        c_actual = COLUMN_CONFIG['affiliate']['commission']

        if c_name in df_aff.columns and c_gmv in df_aff.columns:
            df_aff = df_aff.copy()
            df_aff['GMV_Val'] = df_aff[c_gmv].apply(clean_money)

            # Commission logic V2: prefer est std + est ads; fallback to actual (with note)
            if (c_est_std in df_aff.columns) and (c_est_ads in df_aff.columns):
                df_aff['Comm_Val'] = df_aff[c_est_std].apply(clean_money) + df_aff[c_est_ads].apply(clean_money)
                res['commission_source_note'] = "ä½£é‡‘å£å¾„ï¼šEst.standard + Est.ShopAdsï¼ˆV2ä¸»å£å¾„ï¼‰"
            elif c_actual in df_aff.columns:
                df_aff['Comm_Val'] = df_aff[c_actual].apply(clean_money)
                res['commission_source_note'] = "âš ï¸ ä½£é‡‘å£å¾„é€€åŒ–ï¼šç¼º Est.* å­—æ®µï¼Œä½¿ç”¨ Actual Commission Payment"
            else:
                df_aff['Comm_Val'] = 0.0
                res['commission_source_note'] = "âš ï¸ ä½£é‡‘å­—æ®µç¼ºå¤±ï¼šCommission å°†ä¸º 0"

            leaderboard = df_aff.groupby(c_name).agg({
                'GMV_Val': 'sum',
                'Comm_Val': 'sum',
                c_name: 'count'
            }).rename(columns={'GMV_Val': 'GMV', 'Comm_Val': 'Commission', c_name: 'Orders'}).reset_index()

            leaderboard['ROI'] = leaderboard.apply(lambda x: (x['GMV'] / x['Commission']) if x['Commission'] > 0 else 0.0, axis=1)
            res['leaderboard'] = leaderboard.sort_values('GMV', ascending=False)

            if c_type in df_aff.columns:
                pie_data = df_aff.groupby(c_type)['GMV_Val'].sum().reset_index()
                pie_data.columns = ['Type', 'GMV']
                res['content_pie'] = pie_data

    return res

# ================= 8. ä¸»è®¡ç®—æµç¨‹æ•´åˆ =================
def run_calculation_logic_v2(dfs):
    # normalize headers
    for k, df in dfs.items():
        if df is not None:
            dfs[k] = normalize_headers(df)

    df_orders = dfs.get('orders')
    if df_orders is None:
        return None, {}

    # Required order columns
    col_sku = COLUMN_CONFIG['orders']['sku']
    col_rev = COLUMN_CONFIG['orders']['revenue']
    col_qty = COLUMN_CONFIG['orders']['qty']
    col_oid = COLUMN_CONFIG['orders']['order_id']
    missing = [c for c in [col_sku, col_rev, col_qty, col_oid] if c not in df_orders.columns]
    if missing:
        return None, {"error": f"è®¢å•è¡¨ç¼ºå°‘æ ¸å¿ƒåˆ—ï¼š{missing}"}

    df_orders = df_orders.copy()
    df_orders['SKU_Clean'] = clean_text(df_orders, col_sku)
    df_orders['OID_Clean'] = df_orders[col_oid].apply(convert_scientific_to_str)
    df_orders['Rev_Val'] = pd.to_numeric(df_orders[col_rev], errors='coerce').fillna(0.0)
    df_orders['Qty_Val'] = pd.to_numeric(df_orders[col_qty], errors='coerce').fillna(0.0)

    sku_to_spu_dict = build_sku_to_spu_dict(dfs.get('spu_sku'))
    df_orders['SPU'] = df_orders['SKU_Clean'].map(sku_to_spu_dict).fillna(df_orders['SKU_Clean'])

    time_str = "æœªçŸ¥å‘¨æœŸ"
    max_date = None
    min_date = None
    if ensure_date_column(df_orders):
        dates = df_orders['Date'].dropna()
        if not dates.empty:
            min_date = dates.min()
            max_date = dates.max()
            time_str = f"{min_date.strftime('%Y-%m-%d')} ~ {max_date.strftime('%Y-%m-%d')}"

    # Cancelled / sample
    col_status = COLUMN_CONFIG['orders']['status']
    is_cancelled = df_orders[col_status].astype(str).str.strip().isin(['Cancelled', 'Canceled']) if col_status in df_orders.columns else False
    is_sample = (~is_cancelled) & (df_orders['Rev_Val'] == 0)

    # Cost maps
    map_p = get_cost_map(dfs.get('purchase'), ['é‡‡è´­', 'CNY'])
    map_h = get_cost_map(dfs.get('head'), ['å¤´ç¨‹', 'CNY'])
    map_t = get_cost_map(dfs.get('tail'), ['å°¾ç¨‹', 'CNY'])

    # Sample cost
    df_sample = df_orders[is_sample].copy()
    sku_sample_cost = None
    if not df_sample.empty:
        df_sample['Unit_Cost'] = df_sample['SKU_Clean'].map(map_p).fillna(0) + df_sample['SKU_Clean'].map(map_h).fillna(0) + df_sample['SKU_Clean'].map(map_t).fillna(0)
        df_sample['Total_S'] = df_sample['Qty_Val'] * df_sample['Unit_Cost']
        sku_sample_cost = df_sample.groupby('SKU_Clean')['Total_S'].sum().reset_index().rename(columns={'SKU_Clean': 'SKU', 'Total_S': 'æ€»æ ·å“è´¹'})

    # Affiliate commission (SKU-level) from affiliate orders (optional)
    df_aff = dfs.get('affiliate')
    sku_real_comm = None
    aff_note = ""
    if df_aff is not None:
        df_aff = df_aff.copy()
        c_oid = COLUMN_CONFIG['affiliate']['order_id']
        c_sku = COLUMN_CONFIG['affiliate']['sku']

        c_est_std = COLUMN_CONFIG['affiliate']['commission_est_std']
        c_est_ads = COLUMN_CONFIG['affiliate']['commission_est_ads']
        c_actual = COLUMN_CONFIG['affiliate']['commission']

        if c_oid in df_aff.columns and c_sku in df_aff.columns and ((c_est_std in df_aff.columns and c_est_ads in df_aff.columns) or (c_actual in df_aff.columns)):
            df_aff['OID_Clean'] = df_aff[c_oid].apply(convert_scientific_to_str)
            df_aff['SKU_Clean'] = clean_text(df_aff, c_sku)

            if (c_est_std in df_aff.columns) and (c_est_ads in df_aff.columns):
                df_aff['Comm_Val'] = df_aff[c_est_std].apply(clean_money) + df_aff[c_est_ads].apply(clean_money)
                aff_note = "ä½£é‡‘å£å¾„ï¼šEst.standard + Est.ShopAdsï¼ˆV2ä¸»å£å¾„ï¼‰"
            else:
                df_aff['Comm_Val'] = df_aff[c_actual].apply(clean_money)
                aff_note = "âš ï¸ ä½£é‡‘å£å¾„é€€åŒ–ï¼šç¼º Est.*ï¼Œä½¿ç”¨ Actual Commission Payment"

            sku_real_comm = df_aff.groupby('SKU_Clean')['Comm_Val'].sum().reset_index().rename(columns={'SKU_Clean': 'SKU', 'Comm_Val': 'æ€»è¾¾äººä½£é‡‘'})

    # Ads cost allocation to SKU (optional)
    sku_ads_cost = None
    df_ads = dfs.get('ads')
    df_map = dfs.get('mapping')
    if df_ads is not None and df_map is not None:
        c_pid_ads = COLUMN_CONFIG['ads']['pid']
        c_cost_ads = COLUMN_CONFIG['ads']['cost']
        c_pid_map = find_col_by_keyword_fuzzy(df_map, ['product_id'])
        c_sku_map = find_col_by_keyword_fuzzy(df_map, ['sku'])
        if c_pid_ads in df_ads.columns and c_cost_ads in df_ads.columns and c_pid_map and c_sku_map:
            df_map = df_map.copy()
            df_map['PID_Clean'] = clean_text(df_map, c_pid_map)
            df_map['SKU_Clean'] = clean_text(df_map, c_sku_map)
            pid_grps = df_map.groupby('PID_Clean')['SKU_Clean'].apply(lambda x: list(sorted(set(x.tolist())))).reset_index()

            df_ads2 = df_ads.copy()
            df_ads2['PID_Clean'] = clean_text(df_ads2, c_pid_ads)
            df_ads2['Cost_Raw'] = df_ads2[c_cost_ads].apply(clean_money)

            # SKU revenue map from orders (exclude samples)
            sku_rev_map = df_orders[~is_sample & ~is_cancelled].groupby('SKU_Clean')['Rev_Val'].sum().to_dict()

            dist_list = []
            merged = pd.merge(df_ads2, pid_grps, on='PID_Clean', how='inner')
            for _, row in merged.iterrows():
                cost = float(row['Cost_Raw'] or 0)
                skus = row['SKU_Clean']
                if not skus:
                    continue
                revs = {s: float(sku_rev_map.get(s, 0.0)) for s in skus}
                tot = sum(revs.values())
                for s in skus:
                    share = cost * (revs[s] / tot) if tot > 0 else cost / max(len(skus), 1)
                    dist_list.append({'SKU': s, 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹': share})

            if dist_list:
                sku_ads_cost = pd.DataFrame(dist_list).groupby('SKU')['æ€»å¹¿å‘ŠæŠ•æ”¾è´¹'].sum().reset_index()

    # Build SKU stats: refund-after revenue and qty from non-cancel and non-sample
    df_normal = df_orders[~is_cancelled].copy()
    df_refund = df_orders[is_cancelled].copy()

    sku_stats = df_normal.groupby(['SKU_Clean', 'SPU']).agg({'Rev_Val': 'sum', 'Qty_Val': 'sum'}).reset_index()
    sku_stats.rename(columns={'SKU_Clean': 'SKU', 'Rev_Val': 'é€€æ¬¾åè¥æ”¶', 'Qty_Val': 'é”€é‡'}, inplace=True)

    # Merge add costs
    if sku_real_comm is not None:
        sku_stats = pd.merge(sku_stats, sku_real_comm, on='SKU', how='left')
    if sku_sample_cost is not None:
        sku_stats = pd.merge(sku_stats, sku_sample_cost, on='SKU', how='left')
    if sku_ads_cost is not None:
        sku_stats = pd.merge(sku_stats, sku_ads_cost, on='SKU', how='left')

    for c in ['æ€»è¾¾äººä½£é‡‘', 'æ€»æ ·å“è´¹', 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹']:
        if c not in sku_stats.columns:
            sku_stats[c] = 0.0
        else:
            sku_stats[c] = sku_stats[c].fillna(0.0)

    # Refund orders qty
    if not df_refund.empty:
        ref_agg = df_refund.groupby('SKU_Clean')['Qty_Val'].sum().reset_index().rename(columns={'SKU_Clean': 'SKU', 'Qty_Val': 'Refund_Orders'})
        sku_stats = pd.merge(sku_stats, ref_agg, on='SKU', how='left').fillna({'Refund_Orders': 0.0})
    else:
        sku_stats['Refund_Orders'] = 0.0

    # Unit costs
    sku_stats['å•ä»¶é‡‡è´­æˆæœ¬'] = sku_stats['SKU'].map(map_p).fillna(0.0)
    sku_stats['å•ä»¶å¤´ç¨‹'] = sku_stats['SKU'].map(map_h).fillna(0.0)
    sku_stats['å•ä»¶å°¾ç¨‹'] = sku_stats['SKU'].map(map_t).fillna(0.0)
    sku_stats['å•ä»¶å…³ç¨'] = 0.0

    sku_stats['é‡‡è´­æˆæœ¬'] = sku_stats['å•ä»¶é‡‡è´­æˆæœ¬'] * sku_stats['é”€é‡']
    sku_stats['å¤´ç¨‹'] = sku_stats['å•ä»¶å¤´ç¨‹'] * sku_stats['é”€é‡']
    sku_stats['å°¾ç¨‹'] = sku_stats['å•ä»¶å°¾ç¨‹'] * sku_stats['é”€é‡']
    sku_stats['å…³ç¨'] = 0.0

    # Profit metrics
    df_sku_raw = calculate_metrics_final(sku_stats)
    df_sku_out = format_dataframe(df_sku_raw, TARGET_COLUMNS_SKU)

    # Aggregate to SPU
    cols_to_sum = [
        'é”€é‡', 'é€€æ¬¾åè¥æ”¶', 'é€€æ¬¾å‰è¥æ”¶', 'Refund_Orders', 'é€€æ¬¾è¥æ”¶',
        'é‡‡è´­æˆæœ¬', 'å¤´ç¨‹', 'å°¾ç¨‹', 'å…³ç¨',
        'ä»“ç§Ÿ', 'å…¶ä»–ç‰©æµæˆæœ¬', 'å“ç‰Œè´¹ç”¨', 'å¹³å°ä½£é‡‘', 'å…¶ä»–å’Œå”®å',
        'æ€»è¾¾äººä½£é‡‘', 'æ€»æ ·å“è´¹', 'æ€»å¹¿å‘ŠæŠ•æ”¾è´¹'
    ]
    valid_cols = [c for c in cols_to_sum if c in df_sku_raw.columns]
    spu_agg = df_sku_raw.groupby('SPU')[valid_cols].sum().reset_index()
    df_spu_raw = calculate_metrics_final(spu_agg).sort_values(by='é€€æ¬¾åè¥æ”¶', ascending=False)
    df_spu_out = format_dataframe(df_spu_raw, TARGET_COLUMNS_SPU)

    # Shop aggregate
    shop_agg = df_sku_raw[valid_cols].sum().to_frame().T
    df_shop_raw = calculate_metrics_final(shop_agg)
    df_shop_raw['æ•°æ®å‘¨æœŸ'] = time_str
    df_shop_out = format_dataframe(df_shop_raw, TARGET_COLUMNS_SHOP_FINAL)

    # Ads diagnostics (V2)
    df_prod_ads, df_video_ads, df_ads_detail, ads_meta = process_ads_data_v2(dfs, df_sku_raw)

    # Creator data (V2)
    creator_data = process_creator_data_v2(dfs, df_shop_raw, df_spu_raw)
    if aff_note:
        creator_data['commission_source_note'] = (creator_data.get('commission_source_note', '') + " | " + aff_note).strip(" |")

    meta = {
        "time_str": time_str,
        "max_date": max_date,
        "min_date": min_date,
        "ads_meta": ads_meta
    }

    out = {
        "df_shop_out": df_shop_out, "df_spu_out": df_spu_out, "df_sku_out": df_sku_out,
        "df_shop_raw": df_shop_raw, "df_spu_raw": df_spu_raw, "df_sku_raw": df_sku_raw,
        "df_prod_ads": df_prod_ads, "df_video_ads": df_video_ads,
        "creator_data": creator_data,
        "dfs": dfs
    }
    return out, meta

# ================= 9. æ™ºèƒ½æ–‡ä»¶è¯†åˆ«è¯»å–å™¨ =================
def load_uploaded_files(uploaded_files):
    dfs = {
        'orders': None, 'orders_last_year': None, 'ads': None, 'affiliate': None,
        'spu_sku': None, 'mapping': None, 'purchase': None, 'head': None, 'tail': None,
        'transaction': None
    }
    status_flags = {k: False for k in dfs.keys()}
    debug_logs = []

    file_list = uploaded_files if isinstance(uploaded_files, list) else []
    total = len(file_list)
    progress_bar = st.progress(0)
    status_text = st.empty()

    valid_exts = ['.csv', '.xlsx', '.xls']

    for i, file_obj in enumerate(file_list):
        is_local = isinstance(file_obj, str)
        fname = os.path.basename(file_obj) if is_local else file_obj.name
        fname_lower = fname.lower()

        if fname.startswith('.') or fname.startswith('~$'):
            continue
        if not any(fname_lower.endswith(ext) for ext in valid_exts):
            continue

        status_text.text(f"â³ æ­£åœ¨è§£æ: {fname}...")
        if total > 0:
            progress_bar.progress((i + 1) / total)

        try:
            if fname_lower.endswith('.csv'):
                df = pd.read_csv(file_obj, dtype=str, encoding='utf-8-sig')
            else:
                df = pd.read_excel(file_obj, dtype=str)

            df.columns = df.columns.astype(str).str.strip()
            cols = df.columns.tolist()
            log_info = f"ğŸ“„ **{fname}**\n- åˆ—å‰5: {cols[:5]}\n"
            match_type = "æœªåŒ¹é…"

            # 1. Affiliate
            if COLUMN_CONFIG['affiliate']['creator'] in cols:
                dfs['affiliate'] = df; status_flags['affiliate'] = True
                match_type = "âœ… è”ç›Ÿè®¢å•è¡¨"

            # 2. Transaction
            elif COLUMN_CONFIG['transaction']['aff_gmv'] in cols:
                dfs['transaction'] = df; status_flags['transaction'] = True
                match_type = "âœ… Transactionè¡¨"

            # 3. Ads
            elif 'Campaign name' in cols or 'ad group name' in cols:
                dfs['ads'] = df; status_flags['ads'] = True
                match_type = "âœ… å¹¿å‘Šè¡¨"

            # 4. last year orders
            elif '2025' in fname_lower:
                dfs['orders_last_year'] = df; status_flags['orders_last_year'] = True
                match_type = "âœ… å»å¹´è®¢å•è¡¨"

            # 5. main orders
            elif COLUMN_CONFIG['orders']['order_id'] in cols and COLUMN_CONFIG['orders']['sku'] in cols:
                dfs['orders'] = df; status_flags['orders'] = True
                match_type = "âœ… ä¸»è®¢å•è¡¨"

            # 6. Aux tables by filename
            elif 'spu' in fname_lower:
                dfs['spu_sku'] = df; status_flags['spu_sku'] = True; match_type = "SPUæ˜ å°„"
            elif 'pid' in fname_lower or 'mapping' in fname_lower:
                dfs['mapping'] = df; status_flags['mapping'] = True; match_type = "PIDæ˜ å°„"
            elif 'é‡‡è´­' in fname:
                dfs['purchase'] = df; status_flags['purchase'] = True; match_type = "é‡‡è´­è¡¨"
            elif 'å¤´ç¨‹' in fname:
                dfs['head'] = df; status_flags['head'] = True; match_type = "å¤´ç¨‹è¡¨"
            elif 'å°¾ç¨‹' in fname:
                dfs['tail'] = df; status_flags['tail'] = True; match_type = "å°¾ç¨‹è¡¨"

            log_info += f"- åˆ¤å®šç»“æœ: {match_type}"
            debug_logs.append(log_info)

        except Exception as e:
            st.error(f"âŒ è¯»å–æ–‡ä»¶ {fname} å¤±è´¥: {str(e)}")
            debug_logs.append(f"âŒ **{fname}** è¯»å–å¤±è´¥: {str(e)}")

    time.sleep(0.2)
    status_text.text("âœ… è§£æå®Œæˆï¼")
    progress_bar.empty()
    return dfs, status_flags, debug_logs

# ================= 10. ä¸»ç¨‹åº =================
def main():
    st.title("ğŸš€ TikTok AIè¿è¥ç³»ç»Ÿï¼ˆåˆ©æ¶¦ & å¹¿å‘Š & è¾¾äººï¼‰")

    with st.sidebar:
        st.header("ğŸ“‚ æ•°æ®æºè®¾ç½®")
        mode = st.radio("é€‰æ‹©æ•°æ®æ¥æº", ["â¬†ï¸ æ‰‹åŠ¨ä¸Šä¼ æ–‡ä»¶", "ğŸ“‚ æœ¬åœ°è‡ªåŠ¨è¯»å–ï¼ˆè°ƒè¯•ç”¨ï¼‰"])

        uploaded_files = []
        if mode == "â¬†ï¸ æ‰‹åŠ¨ä¸Šä¼ æ–‡ä»¶":
            st.info("ğŸ’¡ æ”¯æŒ xlsx/csvï¼Œè‡ªåŠ¨å¿½ç•¥å¹²æ‰°æ–‡ä»¶ã€‚")
            uploaded_files = st.file_uploader("è¯·ä¸Šä¼ ä¸šåŠ¡æ•°æ®è¡¨", accept_multiple_files=True, type=['xlsx', 'csv'])
        else:
            st.info("ğŸ’¡ æ­£åœ¨æ‰«æå½“å‰ç›®å½•ä¸‹çš„æ•°æ®æ–‡ä»¶...")
            current_dir = os.getcwd()
            uploaded_files = [os.path.join(current_dir, f) for f in os.listdir(current_dir) if f.endswith(('.csv', '.xlsx', '.xls'))]
            st.write(f"æ‰¾åˆ° {len(uploaded_files)} ä¸ªæ–‡ä»¶")

        dfs, flags, logs = {}, {}, []
        if uploaded_files:
            dfs, flags, logs = load_uploaded_files(uploaded_files)

            st.markdown("### ğŸ“Š æ–‡ä»¶å°±ä½çŠ¶æ€")
            with st.expander("è´¢åŠ¡æ ¸å¿ƒæ•°æ®", expanded=True):
                st.write(f"{'âœ…' if flags.get('orders') else 'âŒ'} è®¢å•è¡¨ï¼ˆå¿…é¡»ï¼‰")
                st.write(f"{'âœ…' if flags.get('ads') else 'âŒ'} å¹¿å‘Šè¡¨")
                st.write(f"{'âœ…' if flags.get('purchase') else 'âŒ'} é‡‡è´­æˆæœ¬")
                st.write(f"{'âœ…' if flags.get('spu_sku') else 'âŒ'} SPUæ˜ å°„")
                st.write(f"{'âœ…' if flags.get('mapping') else 'âŒ'} PIDæ˜ å°„ï¼ˆå»ºè®®ï¼‰")
            with st.expander("è¾¾äººåˆ†ææ•°æ®", expanded=True):
                st.write(f"{'âœ…' if flags.get('affiliate') else 'âŒ'} è”ç›Ÿè®¢å•è¡¨")
                st.write(f"{'âœ…' if flags.get('transaction') else 'âŒ'} Transactionè¡¨")

            with st.expander("ğŸ•µï¸ æ–‡ä»¶è¯Šæ–­è¯¦æƒ…ï¼ˆDebugï¼‰", expanded=False):
                for log in logs:
                    st.markdown(log)
                    st.divider()

        st.divider()
        st.subheader("ğŸ¯ ç›®æ ‡è®¾å®šï¼ˆV2ï¼‰")
        target_revenue = st.number_input("æœ¬æœˆè¥æ”¶ç›®æ ‡ ($)", value=0.0, step=1000.0)
        target_profit_rate = st.number_input("ç›®æ ‡åˆ©æ¶¦ç‡ï¼ˆé»˜è®¤15%ï¼‰", value=0.15, step=0.01, format="%.2f")

    if st.button("ğŸš€ ç‚¹å‡»å¼€å§‹æµ‹ç®—", type="primary", disabled=not flags.get('orders')):
        st.session_state['has_run'] = True
        with st.spinner("â³ æ­£åœ¨è¿›è¡Œï¼šåˆ©æ¶¦æ ¸ç®—ã€å¹¿å‘Šè¯Šæ–­ã€è¾¾äººåˆ†æ..."):
            out, meta = run_calculation_logic_v2(dfs)
            if out is None:
                st.error(meta.get("error", "âŒ è¿è¡Œå¤±è´¥ï¼šæœªçŸ¥é”™è¯¯"))
                st.session_state['has_run'] = False
            else:
                st.session_state['data'] = {"out": out, "meta": meta}
                st.session_state['targets'] = {"target_revenue": target_revenue, "target_profit_rate": target_profit_rate}

    if st.session_state.get('has_run') and st.session_state.get('data'):
        data = st.session_state['data']
        out = data['out']
        meta = data['meta']
        targets = st.session_state.get('targets', {"target_revenue": 0.0, "target_profit_rate": 0.15})

        df_shop_out = out['df_shop_out']
        df_spu_out = out['df_spu_out']
        df_sku_out = out['df_sku_out']

        df_shop_raw = out['df_shop_raw']
        df_spu_raw = out['df_spu_raw']
        df_prod_ads = out['df_prod_ads']
        df_video_ads = out['df_video_ads']
        creator_data = out['creator_data']
        dfs = out['dfs']

        time_str = meta.get("time_str", "æœªçŸ¥å‘¨æœŸ")
        max_date = meta.get("max_date", None)
        min_date = meta.get("min_date", None)
        ads_meta = meta.get("ads_meta", {})

        # Shop core numbers from raw
        shop_row_raw = df_shop_raw.iloc[0]
        curr_rev_after = float(shop_row_raw.get('é€€æ¬¾åè¥æ”¶', 0) or 0)
        curr_gmv_before = float(shop_row_raw.get('é€€æ¬¾å‰è¥æ”¶', 0) or 0)
        curr_profit = float(shop_row_raw.get('åˆ©æ¶¦é¢', 0) or 0)
        curr_profit_rate = float(shop_row_raw.get('åˆ©æ¶¦ç‡', 0) or 0)
        curr_refund_rate = float(shop_row_raw.get('é€€æ¬¾ç‡', 0) or 0)
        curr_mkt_rate = float(shop_row_raw.get('æ€»è¥é”€è´¹æ¯”', 0) or 0)

        target_revenue = float(targets.get("target_revenue", 0) or 0)
        target_profit_rate = float(targets.get("target_profit_rate", 0.15) or 0.15)

        mtd_achieve = (curr_rev_after / target_revenue) if target_revenue > 0 else 0.0

        # Time progress (best-effort)
        time_progress = 0.0
        if max_date is not None:
            try:
                d = pd.to_datetime(max_date)
                days_in_month = pd.Period(d.strftime("%Y-%m")).days_in_month
                time_progress = min(max(d.day / days_in_month, 0.0), 1.0)
            except:
                time_progress = 0.0

        # progress judgment
        def progress_label_revenue(ach, tp):
            if tp <= 0:
                return "â€”"
            if ach >= tp:
                return "ğŸŸ¢ è¿›åº¦å¥åº·"
            if ach >= tp - 0.05:
                return "ğŸŸ¡ è½»å¾®è½å"
            return "ğŸ”´ æ˜æ˜¾è½å"

        rev_judge = progress_label_revenue(mtd_achieve, time_progress) if target_revenue > 0 else "â€”"
        profit_judge = "ğŸŸ¢ è¾¾æ ‡" if curr_profit_rate >= target_profit_rate else "ğŸ”´ ä¸è¾¾æ ‡"

        st.success(f"âœ… æµ‹ç®—æˆåŠŸï¼æ•°æ®å‘¨æœŸ: {time_str}")

        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ  ç»è¥æ€»è§ˆ", "ğŸ“¦ SPU åˆ†æ", "ğŸ“„ SKU æ˜ç»†", "ğŸ“º å¹¿å‘Šæ·±åº¦è¯Šæ–­", "ğŸ¤ è¾¾äººåˆä½œåˆ†æ", "ğŸ§  AI æ“ç›˜æ‰‹"])

        with tab1:
            st.markdown("### ğŸ“ˆ ç»è¥æ€»è§ˆï¼ˆV2ï¼‰")

            c1, c2 = st.columns(2)
            with c1:
                st.markdown(f"""
                <div class="kpi-card">
                  <div class="kpi-title">ğŸ“Š KPU è¿›åº¦</div>
                  <b>è¥æ”¶ç›®æ ‡</b>: ${target_revenue:,.0f} ï½œ <b>å®é™…</b>: ${curr_rev_after:,.0f}ï¼ˆè¾¾æˆ {mtd_achieve:.1%}ï¼‰<br>
                  <b>æœˆåº¦æ—¶é—´è¿›åº¦</b>: {time_progress:.1%} ï½œ <b>è¿›åº¦åˆ¤å®š</b>: {rev_judge}<br><br>
                  <b>ç›®æ ‡åˆ©æ¶¦ç‡</b>: {target_profit_rate:.1%} ï½œ <b>å®é™…åˆ©æ¶¦ç‡</b>: {curr_profit_rate:.1%} ï½œ <b>åˆ¤å®š</b>: {profit_judge}
                </div>
                """, unsafe_allow_html=True)

            with c2:
                st.markdown(f"""
                <div class="kpi-card">
                  <div class="kpi-title">ğŸ’° å¤§ç›˜æ ¸å¿ƒæ•°æ®</div>
                  <b>é€€æ¬¾å‰GMV</b>: ${curr_gmv_before:,.0f}<br>
                  <b>å‡€åˆ©æ¶¦</b>: ${curr_profit:,.0f}<br>
                  <b>é€€æ¬¾ç‡</b>: {curr_refund_rate:.1%} ï½œ <b>è¥é”€è´¹æ¯”</b>: {curr_mkt_rate:.1%}
                  <div class="note">é€€æ¬¾å‰GMV = é€€æ¬¾åè¥æ”¶ +ï¼ˆé€€æ¬¾å•æ•°Ã—ASPä¼°ç®—é€€æ¬¾é¢ï¼‰</div>
                </div>
                """, unsafe_allow_html=True)

            # Trend charts
            trend_df_bw, trend_df_m = get_dual_trend_data(dfs.get('orders'), dfs.get('orders_last_year'))
            if trend_df_bw is not None and not trend_df_bw.empty:
                st.subheader("å‡€è¥æ”¶è¶‹åŠ¿ï¼ˆåŒå‘¨/æŒ‰æœˆï¼‰")
                gran = st.radio("è¶‹åŠ¿ç²’åº¦", ["åŒå‘¨ï¼ˆé»˜è®¤ï¼‰", "æŒ‰æœˆ"], horizontal=True)
                tdf = trend_df_bw if gran.startswith("åŒå‘¨") else trend_df_m
                chart = alt.Chart(tdf).mark_line(point=True).encode(
                    x=alt.X('X:N', title='å‘¨æœŸ', sort=None),
                    y=alt.Y('Revenue:Q', title='å‡€è¥æ”¶ ($)'),
                    color=alt.Color('Year:N', title='å¹´ä»½'),
                    tooltip=[alt.Tooltip('Year:N'), alt.Tooltip('X:N'), alt.Tooltip('Revenue:Q', format=',.2f')]
                ).interactive()
                st.altair_chart(chart, use_container_width=True)

            st.subheader("åº—é“ºç»´åº¦è´¢åŠ¡æ•°æ®è¡¨")
            st.dataframe(df_shop_out, use_container_width=True)

        with tab2:
            # âœ… éœ€æ±‚1 + éœ€æ±‚6ï¼šSPUåˆ†æåŠ å…¥â€œç›ˆäºåˆ†æâ€å’Œâ€œæ³¢å£«é¡¿åˆ†æâ€
            st.markdown("## ğŸ“¦ SPU åˆ†æï¼ˆV2ï¼‰")

            st.markdown("### ğŸ”¥ 1ï¼‰ç›ˆäºåˆ†æï¼ˆå¯è§†åŒ–ï¼‰")
            left, right = st.columns([1.2, 1.0])

            # åˆ©æ¶¦è´¡çŒ® Top10 SPU
            with left:
                st.markdown("#### ğŸ† åˆ©æ¶¦è´¡çŒ® Top 10 SPU")
                if df_spu_raw is None or df_spu_raw.empty or ('SPU' not in df_spu_raw.columns) or ('åˆ©æ¶¦é¢' not in df_spu_raw.columns):
                    st.warning("ç¼ºå°‘ SPU æˆ– åˆ©æ¶¦é¢ å­—æ®µï¼Œæ— æ³•ç”Ÿæˆåˆ©æ¶¦è´¡çŒ®Top10ã€‚")
                else:
                    top_profit = df_spu_raw[['SPU', 'åˆ©æ¶¦é¢']].copy().sort_values('åˆ©æ¶¦é¢', ascending=False).head(10)
                    bar = alt.Chart(top_profit).mark_bar().encode(
                        x=alt.X('åˆ©æ¶¦é¢:Q', title='åˆ©æ¶¦è´¡çŒ®å€¼ï¼ˆå‡€åˆ©æ¶¦ $ï¼‰'),
                        y=alt.Y('SPU:N', sort='-x', title='SPU'),
                        tooltip=[alt.Tooltip('SPU:N'), alt.Tooltip('åˆ©æ¶¦é¢:Q', format=',.2f')]
                    ).properties(height=360)
                    st.altair_chart(bar, use_container_width=True)

            # äºæŸè­¦ç¤ºæ¦œ
            with right:
                st.markdown("#### ğŸ§¨ äºæŸè­¦ç¤ºæ¦œï¼ˆè´Ÿåˆ©æ¶¦ï¼‰")
                req_cols = ['SPU', 'é”€é‡', 'é€€æ¬¾å‰è¥æ”¶', 'é€€æ¬¾å•æ•°', 'é€€æ¬¾åè¥æ”¶', 'åˆ©æ¶¦é¢', 'åˆ©æ¶¦ç‡']
                miss = [c for c in req_cols if (df_spu_raw is None) or (c not in df_spu_raw.columns)]
                if miss:
                    st.warning(f"ç¼ºå°‘å­—æ®µï¼š{miss}ï¼Œæ— æ³•ç”ŸæˆäºæŸè­¦ç¤ºæ¦œã€‚")
                else:
                    loss_df = df_spu_raw[req_cols].copy()
                    loss_df = loss_df[loss_df['åˆ©æ¶¦é¢'] < 0].sort_values('åˆ©æ¶¦é¢', ascending=True).head(10)
                    loss_df = loss_df.rename(columns={'é€€æ¬¾å‰è¥æ”¶': 'é€€æ¬¾å‰GMV', 'é€€æ¬¾å•æ•°': 'é€€æ¬¾æ•°é‡'})
                    # æ ¼å¼åŒ–å±•ç¤º
                    loss_df['åˆ©æ¶¦ç‡'] = loss_df['åˆ©æ¶¦ç‡'].apply(lambda x: f"{float(x):.2%}")
                    st.dataframe(loss_df, use_container_width=True, hide_index=True)

            st.divider()
            st.markdown("### ğŸ§­ 2ï¼‰æ³¢å£«é¡¿åˆ†æï¼ˆSPU çŸ©é˜µï¼‰")

            # æ³¢å£«é¡¿çŸ©é˜µï¼šç¼ºå°‘â€œå¢é•¿ç‡/å¸‚åœºä»½é¢â€çš„çœŸå®å®šä¹‰ï¼Œè¿™é‡Œç”¨â€œè¥æ”¶å æ¯”ï¼ˆé€€æ¬¾åè¥æ”¶å åº—é“ºï¼‰â€ä½œä¸º Shareï¼Œ
            # ç”¨â€œåˆ©æ¶¦ç‡â€ä½œä¸º Quality/Margin ç»´åº¦ï¼Œä¾¿äºè¿è¥å¿«é€Ÿåˆ†å±‚ã€‚
            if df_spu_raw is None or df_spu_raw.empty:
                st.info("SPU raw æ•°æ®ä¸ºç©ºï¼Œæ— æ³•åšæ³¢å£«é¡¿åˆ†æã€‚")
            else:
                need = ['SPU', 'é€€æ¬¾åè¥æ”¶', 'åˆ©æ¶¦ç‡']
                if any(c not in df_spu_raw.columns for c in need):
                    st.warning(f"ç¼ºå°‘å­—æ®µ {need}ï¼Œæ— æ³•åšæ³¢å£«é¡¿åˆ†æã€‚")
                else:
                    bcg = df_spu_raw[['SPU', 'é€€æ¬¾åè¥æ”¶', 'åˆ©æ¶¦ç‡', 'é”€é‡']].copy()
                    total_rev = float(bcg['é€€æ¬¾åè¥æ”¶'].sum() or 0)
                    bcg['è¥æ”¶å æ¯”'] = bcg['é€€æ¬¾åè¥æ”¶'].apply(lambda x: (float(x) / total_rev) if total_rev > 0 else 0.0)

                    x_mid = float(bcg['è¥æ”¶å æ¯”'].median() if not bcg.empty else 0.0)
                    y_mid = float(bcg['åˆ©æ¶¦ç‡'].median() if not bcg.empty else 0.0)

                    def quad(row):
                        x = row['è¥æ”¶å æ¯”']; y = row['åˆ©æ¶¦ç‡']
                        if x >= x_mid and y >= y_mid:
                            return "â­ Starï¼ˆé«˜å æ¯”&é«˜åˆ©æ¶¦ï¼‰"
                        if x >= x_mid and y < y_mid:
                            return "ğŸ„ Cash Cowï¼ˆé«˜å æ¯”&ä½åˆ©æ¶¦ï¼‰"
                        if x < x_mid and y >= y_mid:
                            return "â“ Questionï¼ˆä½å æ¯”&é«˜åˆ©æ¶¦ï¼‰"
                        return "ğŸ¶ Dogï¼ˆä½å æ¯”&ä½åˆ©æ¶¦ï¼‰"

                    bcg['è±¡é™'] = bcg.apply(quad, axis=1)

                    bubble = alt.Chart(bcg).mark_circle().encode(
                        x=alt.X('è¥æ”¶å æ¯”:Q', title='è¥æ”¶å æ¯”ï¼ˆé€€æ¬¾åè¥æ”¶/åº—é“ºï¼‰'),
                        y=alt.Y('åˆ©æ¶¦ç‡:Q', title='åˆ©æ¶¦ç‡'),
                        size=alt.Size('é€€æ¬¾åè¥æ”¶:Q', title='é€€æ¬¾åè¥æ”¶($)'),
                        color=alt.Color('è±¡é™:N', title='æ³¢å£«é¡¿è±¡é™'),
                        tooltip=[
                            alt.Tooltip('SPU:N'),
                            alt.Tooltip('è±¡é™:N'),
                            alt.Tooltip('é€€æ¬¾åè¥æ”¶:Q', format=',.2f'),
                            alt.Tooltip('è¥æ”¶å æ¯”:Q', format='.2%'),
                            alt.Tooltip('åˆ©æ¶¦ç‡:Q', format='.2%'),
                            alt.Tooltip('é”€é‡:Q')
                        ]
                    ).properties(height=420).interactive()

                    vline = alt.Chart(pd.DataFrame({'x': [x_mid]})).mark_rule().encode(x='x:Q')
                    hline = alt.Chart(pd.DataFrame({'y': [y_mid]})).mark_rule().encode(y='y:Q')

                    st.altair_chart(bubble + vline + hline, use_container_width=True)

                    with st.expander("ğŸ“Œ æ³¢å£«é¡¿è±¡é™å£å¾„è¯´æ˜ï¼ˆä¾¿äºä½ å¯¹é½å›¢é˜Ÿç†è§£ï¼‰", expanded=False):
                        st.markdown(f"""
- **æ¨ªè½´ï¼šè¥æ”¶å æ¯”** = SPUé€€æ¬¾åè¥æ”¶ / åº—é“ºé€€æ¬¾åè¥æ”¶ï¼ˆç”¨äºä»£è¡¨â€œè§„æ¨¡/ä»½é¢â€ï¼‰
- **çºµè½´ï¼šåˆ©æ¶¦ç‡** = SPUåˆ©æ¶¦é¢ / SPUé€€æ¬¾åè¥æ”¶ï¼ˆç”¨äºä»£è¡¨â€œè´¨é‡/å¯æŒç»­â€ï¼‰
- åˆ†å‰²çº¿ä¸º**ä¸­ä½æ•°**ï¼šè¥æ”¶å æ¯”â‰ˆ{x_mid:.2%}ï¼Œåˆ©æ¶¦ç‡â‰ˆ{y_mid:.2%}
                        """)

            st.divider()
            st.markdown("### ğŸ“‹ 3ï¼‰SPU åˆ†æè¡¨ï¼ˆæ ¼å¼åŒ–å±•ç¤ºï¼‰")
            st.dataframe(df_spu_out, use_container_width=True)

        with tab3:
            st.subheader("SKU æ˜ç»†è¡¨ï¼ˆæ ¼å¼åŒ–å±•ç¤ºï¼‰")
            st.dataframe(df_sku_out, use_container_width=True)

        with tab4:
            st.markdown("### ğŸ“º å¹¿å‘Šæ·±åº¦è¯Šæ–­ï¼ˆV2ï¼šä¸¤å±‚è¯Šæ–­ï¼‰")

            if isinstance(ads_meta, dict) and ads_meta.get("error"):
                st.error(f"å¹¿å‘Šè¯Šæ–­ä¸å¯ç”¨ï¼š{ads_meta.get('error')}")
            elif df_prod_ads is None or df_prod_ads.empty:
                st.info("ğŸ’¡ æœªä¸Šä¼ å¹¿å‘Šè¡¨æˆ–å¹¿å‘Šè¡¨å­—æ®µä¸è¶³ï¼Œæš‚æ— æ³•è¿›è¡Œå¹¿å‘Šè¯Šæ–­ã€‚")
            else:
                # Top KPIs
                total_cost = float(df_prod_ads['Cost'].sum() or 0)
                total_rev = float(df_prod_ads['Revenue'].sum() or 0)
                total_orders = float(df_prod_ads['Orders'].sum() or 0)
                total_imps = float(df_prod_ads['Imp_Val'].sum() or 0) if 'Imp_Val' in df_prod_ads.columns else 0.0

                roas = (total_rev / total_cost) if total_cost > 0 else 0.0
                cpa_all = (total_cost / total_orders) if total_orders > 0 else 0.0
                cpm_all = (total_cost / total_imps * 1000) if total_imps > 0 else 0.0

                ac1, ac2, ac3, ac4 = st.columns(4)
                ac1.metric("æ€»å¹¿å‘Šè´¹", f"${total_cost:,.0f}")
                ac2.metric("æ€» ROAS", f"{roas:.2f}")
                ac3.metric("æ•´ä½“ CPA", f"${cpa_all:,.2f}")
                ac4.metric("æ•´ä½“ CPM", f"${cpm_all:,.2f}")

                st.divider()
                st.subheader("å±‚çº§ä¸€ï¼šäº§å“ï¼ˆPIDï¼‰ç›ˆäºè¯Šæ–­ï¼ˆè¿™ä¸ªå“èƒ½ä¸èƒ½æ‰“ï¼‰")

                # Matrix chart
                c_chart = alt.Chart(df_prod_ads).mark_circle().encode(
                    x=alt.X('CPA:Q', title='CPA'),
                    y=alt.Y('ROI:Q', title='ROI (ROAS)'),
                    size=alt.Size('Cost:Q', title='Cost'),
                    color=alt.Color('Status:N', title='Status'),
                    tooltip=['Product ID', 'SPU', 'Status', 'Diagnosis', 'Cost', 'ROI', 'CPA', 'CPA_Line', 'CPA_Line_Source']
                ).interactive()
                st.altair_chart(c_chart, use_container_width=True)

                # Detail table
                df_show = df_prod_ads.copy()
                for c in ['ROI', 'CPA', 'CPM', 'CTR', 'CVR', 'CPA_Line']:
                    if c in df_show.columns:
                        df_show[c] = df_show[c].astype(float).round(2)

                # âœ… éœ€æ±‚2å·²ç»åœ¨ process_ads_data_v2 è°ƒé¡ºåºï¼Œè¿™é‡Œåªå±•ç¤º
                st.dataframe(df_show.sort_values('Cost', ascending=False), use_container_width=True)

                # Rule explanation
                thr = ads_meta.get("thr_prod", {})
                st.markdown(f"""
                <div class="kpi-card">
                  <div class="kpi-title">ğŸ“Œ åˆ¤å®šè§„åˆ™è¯´æ˜ï¼ˆV2ï¼‰</div>
                  <b>è§‚å¯ŸæœŸ</b>ï¼šCost &lt; ${COST_OBSERVE:.0f}<br>
                  <b>ğŸŸ¢ çˆ†æ¬¾</b>ï¼šROI &gt; {ROI_BEST:.1f} ä¸” CPA &lt; CPAæ¯›åˆ©çº¿ï¼ˆCPA_Lineï¼‰<br>
                  <b>ğŸ”´ äºæŸ</b>ï¼šROI &lt; {ROI_LOSS:.1f} æˆ– CPA &gt; CPA_Line<br>
                  <b>ğŸŸ¡ å¯ä¼˜åŒ–</b>ï¼šä¸å±äºçˆ†æ¬¾ä¹Ÿä¸å±äºäºæŸ<br><br>
                  <b>äºæŸåˆ†å‰è¯Šæ–­ä¼˜å…ˆçº§</b>ï¼šCVRä½ â†’ CPMé«˜ â†’ CTRä½<br>
                  å½“å‰åŠ¨æ€é˜ˆå€¼ï¼ˆå«åº•çº¿ï¼‰ï¼šCTR_lowâ‰ˆ{thr.get('CTR_low', 0):.2%}ï¼ŒCVR_lowâ‰ˆ{thr.get('CVR_low', 0):.2%}ï¼ŒCPM_highâ‰ˆ${thr.get('CPM_high', 0):.2f}<br>
                  <div class="warn">âš ï¸ ç”±äºå¹¿å‘Šè¡¨æ— æŒ‰å¤©å­—æ®µï¼Œæœ¬ç‰ˆæœ¬ä¸æä¾›â€œæœ€è¿‘3å¤©/è¿‘7å¤©è¡°é€€é¢„è­¦ï¼ˆFatigue Alertï¼‰â€ã€‚</div>
                </div>
                """, unsafe_allow_html=True)

                st.divider()
                st.subheader("å±‚çº§äºŒï¼šç´ æï¼ˆVideoï¼‰è´¨é‡é€è§†ï¼ˆè¿™æ¡è§†é¢‘å¥½åœ¨å“ªï¼‰")

                if df_video_ads is None or df_video_ads.empty:
                    st.info("ğŸ’¡ æœªæ£€æµ‹åˆ°è§†é¢‘æ ‡é¢˜å­—æ®µæˆ–æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç´ æåˆ†æã€‚")
                else:
                    # Hook vs Pitch matrix (2s vs CTR)
                    df_v = df_video_ads.copy()
                    if 'HookRate_2S' in df_v.columns:
                        df_v['HookRate_2S'] = df_v['HookRate_2S'].astype(float)
                    if 'CTR' in df_v.columns:
                        df_v['CTR'] = df_v['CTR'].astype(float)

                    hook_chart = alt.Chart(df_v).mark_circle().encode(
                        x=alt.X('HookRate_2S:Q', title='2s å®Œæ’­ç‡ï¼ˆHookï¼‰'),
                        y=alt.Y('CTR:Q', title='CTRï¼ˆPitchï¼‰'),
                        size=alt.Size('Cost:Q', title='Cost'),
                        color=alt.Color('Creative Type:N', title='ç±»å‹'),
                        tooltip=['SPU', 'Product ID', 'Video title', 'Creative Type', 'ROI', 'CTR', 'CVR', 'RATE_2S', 'RATE_6S', 'AI_Conclusion']
                    ).interactive()
                    st.altair_chart(hook_chart, use_container_width=True)

                    # âœ… éœ€æ±‚4ï¼šè¡¨æ ¼æ ¼å¼åŒ–æ˜¾ç¤º
                    show_cols = ['SPU', 'Product ID', 'Video title', 'Cost', 'Revenue', 'Orders', 'ROI',
                                 'CTR', 'CVR', 'RATE_2S', 'RATE_6S',
                                 'Creative Type', 'AI_Conclusion', 'Next_Action']
                    show_cols = [c for c in show_cols if c in df_video_ads.columns]
                    df_v_show = df_video_ads[show_cols].copy()

                    # ROI 2ä½ï¼›CTR/CVR/2s/6s ç™¾åˆ†æ¯”2ä½
                    if 'ROI' in df_v_show.columns:
                        df_v_show['ROI'] = df_v_show['ROI'].astype(float).round(2)
                    for pc in ['CTR', 'CVR', 'RATE_2S', 'RATE_6S']:
                        if pc in df_v_show.columns:
                            df_v_show[pc] = df_v_show[pc].astype(float).apply(lambda x: f"{x:.2%}")

                    st.dataframe(df_v_show.sort_values('Cost', ascending=False), use_container_width=True)

                    # âœ… è¡¥å……ï¼šæŠŠâ€œåˆ¤æ–­æ ‡å‡†â€ä¹Ÿåœ¨é¡µé¢è¯´æ˜é‡Œç»™åˆ°ï¼ˆä¾¿äºå›¢é˜Ÿå¯¹é½ï¼‰
                    vthr = ads_meta.get("thr_video", {})
                    st.markdown(f"""
                    <div class="kpi-card">
                      <div class="kpi-title">ğŸ§ª ç´ æåˆ†ç±»æ ‡å‡†ï¼ˆæœ¬å‘¨æœŸåŠ¨æ€é˜ˆå€¼ï¼‰</div>
                      <b>é»„é‡‘ç´ æ</b>ï¼šCTR â‰¥ {vthr.get('CTR_high', 0):.2%} ä¸” 2s â‰¥ {vthr.get('RATE2S_high', 0):.2%} ä¸” CVR â‰¥ {vthr.get('CVR_high', 0):.2%}<br>
                      <b>æ ‡é¢˜å…š</b>ï¼šCTR â‰¥ {vthr.get('CTR_high', 0):.2%} ä¸” 6s â‰¤ {vthr.get('RATE6S_low', 0):.2%}<br>
                      <b>æ— æ•ˆç§è‰</b>ï¼š (2s â‰¥ {vthr.get('RATE2S_high', 0):.2%} æˆ– 6s é«˜) ä¸” CVR ä½äºè¯¥å‘¨æœŸ CVR ä¸­ä½æ•°/åº•çº¿<br>
                      <div class="note">é˜ˆå€¼ç”±â€œä¸­ä½æ•° + åº•çº¿â€å…±åŒå†³å®šï¼šæ—¢èƒ½è‡ªé€‚åº”å½“æœŸæµé‡æ°´ä½ï¼Œä¹Ÿé¿å…é˜ˆå€¼è¿‡ä½å¤±çœŸã€‚</div>
                    </div>
                    """, unsafe_allow_html=True)

        with tab5:
            st.markdown("### ğŸ¤ è¾¾äººåˆä½œåˆ†æï¼ˆV2ï¼‰")

            if creator_data.get('commission_source_note'):
                st.info(creator_data['commission_source_note'])

            # Overall achievement (from transaction)
            overall = creator_data.get('overall')
            if overall:
                oc1, oc2, oc3, oc4 = st.columns(4)
                oc1.metric("è¾¾äººGMVï¼ˆTransactionï¼‰", f"${overall['Affiliate_GMV']:,.0f}")
                oc2.metric("è¾¾äººGMVå æ¯”ï¼ˆåˆ†æ¯=é€€æ¬¾å‰GMVï¼‰", f"{overall['Affiliate_Share']:.2%}")
                oc3.metric("ä¸Šçº¿è§†é¢‘æ•°ï¼ˆVideosï¼‰", f"{overall['Videos']:,.0f}")
                oc4.metric("è‡ªå»ºè”è§†é¢‘æ•ˆç‡ï¼ˆGMV/Videoï¼‰", f"${overall['Efficiency']:,.2f}")
            else:
                st.warning("ğŸ’¡ æœªä¸Šä¼  Transaction è¡¨ï¼šæ— æ³•è®¡ç®—è¾¾äººGMVå æ¯”ã€ä¸Šçº¿è§†é¢‘æ•°ã€è§†é¢‘æ•ˆç‡ã€‚")

            st.divider()

            # Leaderboard + pie
            if creator_data.get('leaderboard') is not None:
                c1, c2 = st.columns(2)
                with c1:
                    st.markdown("#### ğŸ‘‘ è¾¾äººè´¡çŒ®æ¦œ")
                    st.dataframe(creator_data['leaderboard'].head(15), use_container_width=True, hide_index=True)
                with c2:
                    st.markdown("#### ğŸ“Š åœºåŸŸåˆ†å¸ƒï¼ˆContent Typeï¼‰")
                    if creator_data.get('content_pie') is not None:
                        pie = alt.Chart(creator_data['content_pie']).mark_arc(innerRadius=50).encode(
                            theta=alt.Theta('GMV:Q'), color='Type:N', tooltip=['Type', 'GMV']
                        )
                        st.altair_chart(pie, use_container_width=True)
            else:
                st.info("ğŸ’¡ æœªä¸Šä¼ è”ç›Ÿè®¢å•è¡¨ï¼šæ— æ³•ç”Ÿæˆè¾¾äººè´¡çŒ®æ¦œä¸åœºåŸŸåˆ†å¸ƒã€‚")

            st.divider()

            # SPU performance
            if creator_data.get('spu_perf') is not None:
                st.markdown("#### ğŸ“¦ æ ¸å¿ƒ SPU å¸¦è´§è¡¨ç°ï¼ˆæŒ‰ Affiliate GMV é™åºï¼‰")
                df_sp = creator_data['spu_perf'].copy()
                if 'Affiliate_Rate' in df_sp.columns:
                    df_sp['Affiliate_Rate'] = df_sp['Affiliate_Rate'].astype(float).round(4)
                if 'OutputPerVideo' in df_sp.columns:
                    df_sp['OutputPerVideo'] = df_sp['OutputPerVideo'].astype(float).round(2)
                st.dataframe(df_sp, use_container_width=True, hide_index=True)
            else:
                st.info("ğŸ’¡ æœªä¸Šä¼  Transaction æˆ–ç¼ºå°‘ PID æ˜ å°„ï¼šæ— æ³•ç”Ÿæˆ SPU çº§æ¸—é€ä¸å•è§†é¢‘äº§å‡ºã€‚")

        with tab6:
            st.markdown("#### ğŸ§  AI æ“ç›˜æ‰‹ï¼ˆå ä½ï¼‰")
            if st.button("âœ¨ ç”Ÿæˆ Prompt"):
                st.code(f"è¯·åˆ†æå¤§ç›˜æ•°æ®ï¼šé€€æ¬¾åè¥æ”¶ ${curr_rev_after:,.0f}ï¼Œé€€æ¬¾å‰GMV ${curr_gmv_before:,.0f}ï¼Œåˆ©æ¶¦ç‡ {curr_profit_rate:.2%}...")

if __name__ == '__main__':
    main()


